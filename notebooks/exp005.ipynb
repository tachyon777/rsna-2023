{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp005  \n",
    "[Notion](https://www.notion.so/exp005-acda5e00fb014299a3e4b822e7bba837?pvs=4)  \n",
    "3D-CNNによる固形臓器(Liver, Spleen, Kidney)損傷の検出のために、セグメンテーションした臓器を切り抜き保存。  \n",
    "提出時にこの切り抜きを再現できるように、コードをスクリプト化。  \n",
    "本来リークを考慮し学習データはoofで推論すべきだが、全臓器に対するDice係数の平均が0.95を超えているので、あまり大きな問題にはならないと捉え、そのままリークさせて推論・保存する。  \n",
    "新たにデータセットのディレクトリ(`dataset002`)を作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from typing import Any, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import animation, rc\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams['animation.embed_limit'] = 70\n",
    "\n",
    "# リポジトリtopに移動\n",
    "while os.path.basename(os.getcwd()) != 'rsna-2023':\n",
    "    os.chdir('../')\n",
    "    if os.getcwd() == '/':\n",
    "        raise Exception('Could not find project root directory.')\n",
    "    \n",
    "from src.segmentation.dataset import TestDataset, load_df\n",
    "from src.image_processing import windowing\n",
    "from src.visualization import apply_colormap_to_multilabel_images, animate, print_injury\n",
    "from src.metrics import calc_cfm_metrics\n",
    "from src.segmentation.model import load_models\n",
    "from src.segmentation.trainer import evaluate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    exp_name = 'exp_004'\n",
    "    # model config\n",
    "    backbone = 'efficientnet-b3'\n",
    "    n_ch = 1\n",
    "    n_class = 4 # 学習時は腎臓の左右を区別しないので、5->4\n",
    "    # hyper params\n",
    "    init_lr = 1e-3\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-4\n",
    "    image_size = (512, 512)\n",
    "    batch_size = 32\n",
    "    amp = True\n",
    "    n_epoch = 20\n",
    "    iteration_per_epoch = 200\n",
    "    pretrain = True\n",
    "    freeze_epochs = 1\n",
    "    noaug_epochs = 1\n",
    "    # fold config\n",
    "    n_fold = 6\n",
    "    include_evaluation = False\n",
    "    train_folds = 1\n",
    "    # path\n",
    "    image_dir = \"data/dataset001/train_images\"\n",
    "    mask_dir = \"data/dataset001/segmentations\"\n",
    "    model_save_dir = \"outputs\"\n",
    "    # other config\n",
    "    seed = 42\n",
    "    num_workers = 0\n",
    "    num_gpus = 2\n",
    "    progress_bar = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/rsna-2023-abdominal-trauma-detection/train.csv')\n",
    "df_train_image_level = pd.read_csv('data/rsna-2023-abdominal-trauma-detection/image_level_labels.csv')\n",
    "df_train_series_meta = pd.read_csv('data/rsna-2023-abdominal-trauma-detection/train_series_meta.csv')\n",
    "base_dir = \"data/rsna-2023-abdominal-trauma-detection\"\n",
    "dataset_dir = \"data/dataset002\"\n",
    "\n",
    "# get label correspondences\n",
    "organ_index_dict_inv = {\n",
    "    0: 'liver',\n",
    "    1: 'spleen',\n",
    "    2: 'kidney',\n",
    "    3: 'bowel'\n",
    "}\n",
    "organ_index_dict = {v: k for k, v in organ_index_dict_inv.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe():\n",
    "    \"\"\"データセットのDataFrameを作成する.\n",
    "    データセットによって内容を書き換える必要あり.\n",
    "    \"\"\"\n",
    "    # df_train_series_metaをベースに、データフレームを構築.\n",
    "    image_paths = []\n",
    "    pid_list = []\n",
    "    sid_list = []\n",
    "    for i in range(len(df_train_series_meta)):\n",
    "        sr = df_train_series_meta.iloc[i]\n",
    "        pid, sid = sr[\"patient_id\"], sr[\"series_id\"]\n",
    "        pid, sid = int(pid), int(sid)\n",
    "        dir_ = f\"data/dataset001/train_images/{pid}/{sid}\"\n",
    "        path_list = os.listdir(dir_)\n",
    "        path_list = [[int(path.replace(\".npy\",\"\")), path] for path in path_list]\n",
    "        path_list.sort()\n",
    "        path_list = [path[1] for path in path_list]\n",
    "        for path in path_list:\n",
    "            image_paths.append(os.path.join(dir_, path))\n",
    "            pid_list.append(pid)\n",
    "            sid_list.append(sid)\n",
    "    # 画像データのDataFrameを作成\n",
    "    df = pd.DataFrame({\n",
    "            'image_path': image_paths,\n",
    "            'patient_id': pid_list,\n",
    "            'series_id': sid_list,\n",
    "            })\n",
    "    return df\n",
    "\n",
    "df = get_dataframe()\n",
    "# mask_pathという空のカラムを追加\n",
    "df[\"mask_path\"] = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "models = load_models(CFG, mode=\"final\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Code  \n",
    "- シリーズごとの推論の準備\n",
    "- セグメンテーションの前処理及び後処理\n",
    "- 臓器抽出後の分割・保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_series_from_dataset(dir_: str)-> np.ndarray:\n",
    "    \"\"\"seriesを読み込む.\"\"\"\n",
    "    path_list = os.listdir(dir_)\n",
    "    path_list = [[int(path.replace(\".npy\",\"\")), path] for path in path_list]\n",
    "    path_list.sort()\n",
    "    path_list = [path[1] for path in path_list]\n",
    "    arr = []\n",
    "    for path in path_list:\n",
    "        arr.append(np.load(os.path.join(dir_, path)))\n",
    "    return np.array(arr)\n",
    "\n",
    "def apply_preprocess(image: np.ndarray, mask: np.ndarray)-> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"データ前処理. カスタマイズして使用.\n",
    "    Args:\n",
    "        image (numpy.ndarray): HU値のCT画像.\n",
    "        mask (numpy.ndarray): channel lastのマスク画像.\n",
    "    Returns:\n",
    "        image (numpy.ndarray): windowing及び0~1に正規化.\n",
    "        mask (numpy.ndarray): channel lastのマスク画像.\n",
    "    \"\"\"\n",
    "    # 0~1に正規化\n",
    "    image = windowing(image, wl=0, ww=400, mode=\"float32\")\n",
    "    return image, mask\n",
    "\n",
    "def morpho_pytorch(masks):\n",
    "    for c in range(masks.shape[-1]):\n",
    "        with torch.no_grad():\n",
    "            arr = torch.tensor(masks[...,c][np.newaxis]).to(CFG.device).to(torch.float32)\n",
    "            #dialation\n",
    "            arr = torch.nn.MaxPool3d(3, stride=1, padding=1, dilation=1, return_indices=False, ceil_mode=False)(arr)\n",
    "            #erosion\n",
    "            arr = -torch.nn.MaxPool3d(3, stride=1, padding=1, dilation=1, return_indices=False, ceil_mode=False)(-arr)\n",
    "        arr = arr.squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "        masks[...,c] = arr\n",
    "    return masks\n",
    "\n",
    "# 各臓器に対して、一定閾値以下のボクセルの集合を切り捨てる\n",
    "area_th = {\n",
    "    \"liver\":50,\n",
    "    \"spleen\":20,\n",
    "    \"kidney\":20,\n",
    "    \"bowel\":30,\n",
    "}\n",
    "\n",
    "def area_0fill(masks):\n",
    "    for idx,mask in enumerate(masks):\n",
    "        for c,th in area_th.items():\n",
    "            c_idx = organ_index_dict[c]\n",
    "            \n",
    "            contours = cv2.findContours(mask[...,c_idx],cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            contours = contours[0] #0番目は元画像,2番目は階層構造。新しいopencvだと1番目のみがコンツーリング情報っぽい\n",
    "            for con in contours:\n",
    "                area = cv2.contourArea(con)\n",
    "                if area <= area_th[c]:\n",
    "                    fill_mask = mask[...,c_idx].copy()\n",
    "                    fill_mask = cv2.drawContours(fill_mask, [con], 0, 0, -1)\n",
    "                    masks[idx,:,:,c_idx] =  fill_mask\n",
    "    return masks\n",
    "\n",
    "def apply_postprocess(mask: np.ndarray)-> np.ndarray:\n",
    "    \"\"\"セグメンテーション後の臓器マスクの後処理.\n",
    "    Args:\n",
    "        mask (numpy.ndarray): (Z, H, W, C)のマスク画像.\n",
    "    \"\"\"\n",
    "    mask = morpho_pytorch(mask)\n",
    "    # mask = area_0fill(mask)\n",
    "    return mask\n",
    "\n",
    "def evaluate_series(CFG: Any, df: pd.DataFrame, models: list, pid: int, sid: int) -> dict:\n",
    "    \"\"\"患者ごと(シリーズごと)の評価を行う.\n",
    "    Args:\n",
    "        CFG (Any): Config\n",
    "        df (pd.DataFrame): get_training_dataframeによって作成したdf\n",
    "        models (list): 学習済みモデルのリスト\n",
    "        pid (int): 患者ID\n",
    "        sid (int): シリーズID\n",
    "    Returns:\n",
    "        dict: 評価結果\n",
    "    \"\"\"\n",
    "    # 評価用データセットの作成\n",
    "    df_res = df[(df[\"patient_id\"] == pid) & (df[\"series_id\"] == sid)].reset_index(drop=True)\n",
    "    if len(df_res) == 0:\n",
    "        raise ValueError(f\"pid:{pid}, sid:{sid} is not found.\")\n",
    "    ds = TestDataset(CFG, df_res, preprocess=apply_preprocess)\n",
    "    eval_iterator = DataLoader(\n",
    "        ds,\n",
    "        shuffle=False,\n",
    "        batch_size=CFG.batch_size,\n",
    "        num_workers=CFG.num_workers\n",
    "    )\n",
    "    # 推論\n",
    "    result = evaluate(CFG, models, eval_iterator)\n",
    "    return result\n",
    "\n",
    "def crop_organ(image: np.ndarray, mask: np.ndarray)-> np.ndarray:\n",
    "    \"\"\"臓器のみを切り抜き、臓器に外接するボリュームを返す.\"\"\"\n",
    "    # 臓器が存在する部分のインデックスを取得\n",
    "    z_indices, h_indices, w_indices = np.where(mask != 0)\n",
    "\n",
    "    \"\"\"# 各軸に沿って最小と最大のインデックスを見つける\n",
    "    z_min, z_max = np.min(z_indices), np.max(z_indices)\n",
    "    h_min, h_max = np.min(h_indices), np.max(h_indices)\n",
    "    w_min, w_max = np.min(w_indices), np.max(w_indices)\"\"\"\n",
    "\n",
    "    # 各軸に沿って、p%のボクセルが含まれる範囲を見つける\n",
    "    p = 98\n",
    "    z_min, z_max = np.percentile(z_indices, 100-p), np.percentile(z_indices, p)\n",
    "    h_min, h_max = np.percentile(h_indices, 100-p), np.percentile(h_indices, p)\n",
    "    w_min, w_max = np.percentile(w_indices, 100-p), np.percentile(w_indices, p)\n",
    "    z_min, z_max = int(z_min), int(z_max)\n",
    "    h_min, h_max = int(h_min), int(h_max)\n",
    "    w_min, w_max = int(w_min), int(w_max)\n",
    "\n",
    "    # この範囲でセグメンテーションデータを切り抜く\n",
    "    margin = 10\n",
    "    z_min, z_max = max(0, z_min - 5), min(image.shape[0], z_max + 5)\n",
    "    h_min, h_max = max(0, h_min - margin), min(image.shape[1], h_max + margin)\n",
    "    w_min, w_max = max(0, w_min - margin), min(image.shape[2], w_max + margin)\n",
    "    cropped_image = image[z_min:z_max+1, h_min:h_max+1, w_min:w_max+1]\n",
    "    cropped_mask = mask[z_min:z_max+1, h_min:h_max+1, w_min:w_max+1]\n",
    "\n",
    "    # crop segmentation\n",
    "    # cropped_image = cropped_image * cropped_mask + (1 - cropped_mask) * -1000\n",
    "\n",
    "    return cropped_image, cropped_mask\n",
    "\n",
    "def kidney_split(image: np.ndarray, mask: np.ndarray)-> np.ndarray:\n",
    "    \"\"\"腎臓について、一度crop_organに入力したものを再度この関数に入力することで左右の腎臓に切り出す.\n",
    "    Note:\n",
    "        本関数中のleft/rightは画像上のleft_rightを表す.\n",
    "    \"\"\"\n",
    "    w_half = image.shape[2] // 2\n",
    "    left_image = image[:, :, :w_half]\n",
    "    left_mask = mask[:, :, :w_half]\n",
    "    right_image = image[:, :, w_half:]\n",
    "    right_mask = mask[:, :, w_half:]\n",
    "    left_image, _ = crop_organ(left_image, left_mask)\n",
    "    right_image, _ = crop_organ(right_image, right_mask)\n",
    "    return left_image, right_image\n",
    "\n",
    "def resize_volume(mask: np.ndarray, hw_shape: tuple)-> np.ndarray:\n",
    "    \"\"\"h, wが512ではない場合にmaskをimageに合うようにリサイズする.\"\"\"\n",
    "    new_arr = []\n",
    "    for i in range(mask.shape[0]):\n",
    "        new_arr.append(cv2.resize(mask[i], hw_shape[::-1]))\n",
    "    return np.stack(new_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference() -> None:\n",
    "    \"\"\"学習用全データに対するセグメンテーション推論を行う.\n",
    "    切り抜いた臓器のCT画像を保存する.\n",
    "    保存は、f'{pid}_{sid}_{organ}.npy'という形式で、スライス位置などの情報を付加せずに外接矩形で保存.\n",
    "    ボリュームサイズは制限せず、元の解像度で保存.\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(len(df_train_series_meta))):\n",
    "        pid, sid = df_train_series_meta.iloc[i][[\"patient_id\", \"series_id\"]]\n",
    "        pid, sid = int(pid), int(sid)\n",
    "        result = evaluate_series(CFG, df, models, pid, sid)\n",
    "        image_dir = f\"data/dataset001/train_images/{pid}/{sid}\"\n",
    "        image = load_series_from_dataset(image_dir)\n",
    "        pred = result[\"pred\"] # (Z, H, W, C)\n",
    "        pred = (pred > 0.5).astype(np.uint8)\n",
    "        pred = apply_postprocess(pred)\n",
    "        # imageが512x512でない場合はmask側をリサイズ\n",
    "        if (image.shape[1], image.shape[2]) != CFG.image_size:\n",
    "            pred = resize_volume(pred, image.shape[1:])\n",
    "\n",
    "        for organ in [\"kidney\", \"liver\", \"spleen\"]:\n",
    "            organ_idx = organ_index_dict[organ]\n",
    "            organ_segment = pred[..., organ_idx]\n",
    "            if organ_segment.sum() == 0:\n",
    "                continue\n",
    "            organ_cropped, mask_cropped = crop_organ(image, organ_segment)\n",
    "            save_dir = os.path.join(dataset_dir, str(pid), str(sid))\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            if organ == \"kidney\":\n",
    "                kidney_r, kidney_l = kidney_split(organ_cropped, mask_cropped)\n",
    "                path = os.path.join(save_dir, \"kidney_r.npy\")\n",
    "                np.save(path, kidney_r)\n",
    "                path = os.path.join(save_dir, \"kidney_l.npy\")\n",
    "                np.save(path, kidney_l)\n",
    "            else:\n",
    "                path = os.path.join(save_dir, f\"{organ}.npy\")\n",
    "                np.save(path, organ_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4711/4711 [10:09:13<00:00,  7.76s/it]  \n"
     ]
    }
   ],
   "source": [
    "inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop boxel shape: (50, 94, 102)\n",
      "healty patient\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pid, sid = 10082, 8139\n",
    "organ = \"kidney_l\"\n",
    "ct_crop = np.load(f\"/home/medphys3/competition/rsna-2023/data/dataset002/{pid}/{sid}/{organ}.npy\")\n",
    "print(f\"crop boxel shape: {ct_crop.shape}\")\n",
    "dir_ = f\"/home/medphys3/competition/rsna-2023/data/dataset001/train_images/{pid}/{sid}\"\n",
    "ct = load_series_from_dataset(dir_)\n",
    "print_injury(df_train, pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_crop_w = windowing(ct_crop, 0, 400)\n",
    "ct_crop_w[:,0,0] = 255\n",
    "animate(ct_crop_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate(windowing(ct))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
