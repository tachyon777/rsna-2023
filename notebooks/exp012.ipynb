{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp012\n",
    "[Notion](https://www.notion.so/exp012-1ed9dc9b29ff41cdbb9493131c83ece4?pvs=4)  \n",
    "exp004,009,011によって作成した深層学習モデルにより、コンペ提出用のパイプラインを構築する."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import defaultdict\n",
    "from typing import Tuple, Any, Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# リポジトリtopに移動\n",
    "while os.path.basename(os.getcwd()) != 'rsna-2023':\n",
    "    os.chdir('../')\n",
    "    if os.getcwd() == '/':\n",
    "        raise Exception('Could not find project root directory.')\n",
    "    \n",
    "from src.data_io import load_dicom_series\n",
    "from src.segmentation.dataset import TestDataset as SegTestDataset\n",
    "from src.segmentation.model import load_models as seg_load_models\n",
    "from src.segmentation.trainer import evaluate as seg_evaluate\n",
    "from src.classification.dataset import TestDatasetBowelExtra, TestDatasetSolidOrgans\n",
    "from src.image_processing import apply_preprocess, crop_organ, kidney_split, resize_volume, apply_postprocess, kidney_specific, resize_3d\n",
    "from src.classification.model import load_models as cls_load_models\n",
    "from src.classification.trainer import evaluate as cls_evaluate\n",
    "from src.metrics import logloss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG_INF:\n",
    "    exp_name = 'exp_012'\n",
    "    # evaluation時：'train', submission時：'test'\n",
    "    phase = 'train'\n",
    "    base_dir = 'data/rsna-2023-abdominal-trauma-detection'\n",
    "    image_dir = f'data/rsna-2023-abdominal-trauma-detection/{phase}_images'\n",
    "    # dataframeはこのconfigにもたせ、phaseで対応できるようにする.\n",
    "    if phase == 'train':\n",
    "        df = pd.read_csv(os.path.join(base_dir, 'train.csv'))\n",
    "    elif phase == 'test':\n",
    "        df = pd.read_csv(os.path.join(base_dir, 'sample_submission.csv'))\n",
    "    df_serirs_meta = pd.read_csv(os.path.join(base_dir, f'{phase}_series_meta.csv'))\n",
    "    image_size = (512, 512)\n",
    "\n",
    "class CFG_SEG:\n",
    "    exp_name = 'exp_004'\n",
    "    # model config\n",
    "    backbone = 'efficientnet-b3'\n",
    "    n_ch = 1\n",
    "    n_class = 4 # 学習時は腎臓の左右を区別しないので、5->4\n",
    "    # hyper params\n",
    "    init_lr = 1e-3\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-4\n",
    "    image_size = (512, 512)\n",
    "    batch_size = 32\n",
    "    amp = True\n",
    "    n_epoch = 20\n",
    "    iteration_per_epoch = 200\n",
    "    pretrain = True\n",
    "    freeze_epochs = 1\n",
    "    noaug_epochs = 1\n",
    "    # fold config\n",
    "    n_fold = 6\n",
    "    include_evaluation = False\n",
    "    train_folds = 1\n",
    "    # path\n",
    "    image_dir = \"data/dataset001/train_images\"\n",
    "    mask_dir = \"data/dataset001/segmentations\"\n",
    "    model_save_dir = \"outputs\"\n",
    "    # other config\n",
    "    seed = 42\n",
    "    num_workers = 0\n",
    "    num_gpus = 2\n",
    "    progress_bar = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class CFG_LSK:\n",
    "    exp_name = 'exp_009'\n",
    "    # model config\n",
    "    # timm backbone\n",
    "    backbone = 'efficientnet-b1'\n",
    "    n_ch = 1\n",
    "    expand_ch_dim = True\n",
    "    # n_class: healthy, low, high\n",
    "    n_class = 3\n",
    "    # hyper params\n",
    "    init_lr = 1e-4\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-4\n",
    "    image_size = (128, 128, 128)\n",
    "    batch_size = 64\n",
    "    amp = True\n",
    "    n_epoch = 20\n",
    "    pretrain = False\n",
    "    freeze_epochs = 0\n",
    "    noaug_epochs = 1\n",
    "    # fold config\n",
    "    n_fold = 6\n",
    "    include_evaluation = False\n",
    "    train_folds = 1\n",
    "    # path\n",
    "    image_dir = \"data/dataset002\"\n",
    "    model_save_dir = \"outputs\"\n",
    "    # other config\n",
    "    seed = 42\n",
    "    num_workers = 0\n",
    "    num_gpus = 2\n",
    "    progress_bar = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class CFG_BE:\n",
    "    exp_name = 'exp_011'\n",
    "    # model config\n",
    "    # timm backbone\n",
    "    backbone = 'efficientnet_b4'\n",
    "    # n_ch: z軸方向のスライス数\n",
    "    n_ch = 1 # support only 1\n",
    "    expand_ch_dim = False\n",
    "    # n_class: bowel_injury, extravasation\n",
    "    n_class = 2\n",
    "    label_smoothing = None #Optional(float)\n",
    "    # hyper params\n",
    "    init_lr = 5e-5\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-4\n",
    "    image_size = (512, 512)\n",
    "    batch_size = 64\n",
    "    amp = True\n",
    "    n_epoch = 20\n",
    "    iteration_per_epoch = 100\n",
    "    pretrain = True\n",
    "    freeze_epochs = 1\n",
    "    noaug_epochs = 1\n",
    "    # fold config\n",
    "    n_fold = 6\n",
    "    include_evaluation = False\n",
    "    train_folds = 1\n",
    "    # path\n",
    "    image_dir = \"data/dataset001\"\n",
    "    model_save_dir = \"outputs\"\n",
    "    # other config\n",
    "    seed = 42\n",
    "    num_workers = 0\n",
    "    num_gpus = 2\n",
    "    progress_bar = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organs dict (for SEG and LSK models)\n",
    "organ_index_dict_inv = {\n",
    "    0: 'liver',\n",
    "    1: 'spleen',\n",
    "    2: 'kidney',\n",
    "    3: 'bowel'\n",
    "}\n",
    "organ_index_dict = {v: k for k, v in organ_index_dict_inv.items()}\n",
    "\n",
    "# labels dict (for BE models)\n",
    "label_index_dict_inv = {\n",
    "    0: 'bowel_injury',\n",
    "    1: 'extravasation'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    \"\"\"推論パイプライン.\"\"\"\n",
    "    def __init__(self,CFG_INF: Any, CFG_SEG: Any, CFG_LSK: Any, CFG_BE: Any):\n",
    "        self.CFG_INF = CFG_INF\n",
    "        self.CFG_SEG = CFG_SEG\n",
    "        self.CFG_LSK = CFG_LSK\n",
    "        self.CFG_BE = CFG_BE\n",
    "\n",
    "        self.seg_models = seg_load_models(CFG_SEG)\n",
    "        self.lsk_models = cls_load_models(CFG_LSK)\n",
    "        self.be_models = cls_load_models(CFG_BE, framework=\"timm\")\n",
    "    \n",
    "    def __call__(self, pid: int) -> tuple:\n",
    "        \"\"\"inference process.\n",
    "        1. load images from dicom files.\n",
    "        2. create segmentation masks.\n",
    "        3. create liver, spleen, kidney volumes.\n",
    "        4. inference lsk models.\n",
    "        5. inference be models.\n",
    "        Args:\n",
    "            pid (int): patient id.\n",
    "        Return example:\n",
    "            dict: {\n",
    "            'pid': 0,\n",
    "            'bowel_healthy': 0.0,\n",
    "            'bowel_injury': 0.0,\n",
    "            'extravasation_healthy': 0.0,\n",
    "            'extravasation_injury': 0.0,\n",
    "            'kidney_healthy': 0.0,\n",
    "            'kidney_low': 0.0,\n",
    "            'kidney_high': 0.0,\n",
    "            'liver_healthy': 0.0,\n",
    "            'liver_low': 0.0,\n",
    "            'liver_high': 0.0,\n",
    "            'spleen_healthy': 0.0,\n",
    "            'spleen_low': 0.0,\n",
    "            'spleen_high': 0.0\n",
    "            }\n",
    "        Note:\n",
    "            - １症例に複数シリーズ存在する場合、各シリーズに対して推論を行い、全予測結果の最大値を採用する.\n",
    "            - 推論時間的に厳しければ、最初のシリーズのみを採用するなど検討.\n",
    "        \"\"\"\n",
    "        df_stydy = self.CFG_INF.df_series_meta[self.CFG_INF.df_series_meta['patient_id']==pid]\n",
    "        preds = defaultdict(list)\n",
    "        for sid in df_stydy['study_id'].values:\n",
    "            data = self.load_data(pid, sid)\n",
    "            lsk_preds = self.lsk_prediction(data)\n",
    "            be_preds = self.be_prediction(data)\n",
    "            for idx, organ in organ_index_dict_inv.items():\n",
    "                if idx == 3:\n",
    "                    continue\n",
    "                preds[organ].append(lsk_preds[idx])\n",
    "            for idx, label in label_index_dict_inv.items():\n",
    "                preds[label].append(be_preds[idx])\n",
    "\n",
    "        ret = {'pid': pid}\n",
    "        for k,v in preds.items():\n",
    "            ret[k] = np.max(v)\n",
    "        ret = self.convert_submission_format(ret)\n",
    "        return ret\n",
    "\n",
    "    def load_data(self, pid: int, sid: int)-> np.ndarray:\n",
    "        \"\"\"dicomから画像を読み込む.\n",
    "        Args:\n",
    "            pid (int): patient id.\n",
    "            sid (int): series id.\n",
    "        Returns:\n",
    "            np.ndarray: (Z, H, W) normalized CT series.\n",
    "        Note:\n",
    "            - preprocessは全モデル共通なので、ここで行う.\n",
    "        \"\"\"\n",
    "        series_path = os.path.join(self.CFG_INF.image_dir, str(pid), str(sid))\n",
    "        image_arr, path_list, meta_list = load_dicom_series(series_path)\n",
    "        image_arr = apply_preprocess(image_arr, resize=self.CFG_INF.image_size)\n",
    "        return image_arr\n",
    "    \n",
    "    def lsk_prediction(self, data: np.ndarray)-> np.ndarray:\n",
    "        \"\"\"liver, spleen, kidneyの予測値を返す.\n",
    "        Args:\n",
    "            data: (Z, H, W).\n",
    "        Returns:\n",
    "            np.ndarray: (organs, grades).\n",
    "        \"\"\"\n",
    "        volumes = self.get_lsk_volumes(data) # (organs, z, h, w)\n",
    "        lsk_iterator = self.pseudo_iterator(self.CFG_LSK, volumes)\n",
    "        lsk_result = cls_evaluate(self.CFG_LSK, self.lsk_models, lsk_iterator)\n",
    "        pred = lsk_result[\"pred\"]\n",
    "        return pred\n",
    "\n",
    "    def get_lsk_volumes(self, data: np.ndarray)->Dict[str:np.ndarray]:\n",
    "        \"\"\"Segmentationからliver, spleen, kidneyのvolume dataを作成.\n",
    "        Args:\n",
    "            data: (Z, H, W).\n",
    "        Returns:\n",
    "            np.ndarray: (organs, z, h, w).\n",
    "        Note:\n",
    "            - organsはliver, spleen, kidneyの順番.\n",
    "            - この関数内でCFG.LSK.image_shapeのreshapeまで行う.\n",
    "            - 腎臓は左右を分離してからくっつけ直すという特殊な処理が必要.\n",
    "        \"\"\"\n",
    "        masks = self.get_segmentation(data)\n",
    "        masks = apply_postprocess(masks)\n",
    "        arr = []\n",
    "        for idx, organ in organ_index_dict_inv.items():\n",
    "            if idx == 3:\n",
    "                continue\n",
    "            organ_segment = masks[..., idx]\n",
    "            img_cropped, mask_cropped = crop_organ(data, organ_segment)\n",
    "            if organ == \"kidney\":\n",
    "                kidney_r, kidney_l = kidney_split(img_cropped, mask_cropped)\n",
    "                img_cropped = kidney_specific(self.CFG_LSK, kidney_r, kidney_l)\n",
    "            else:\n",
    "                img_cropped = resize_3d(img_cropped, self.CFG_LSK.image_shape)\n",
    "            arr.append(img_cropped)\n",
    "        arr = np.stack(arr, axis=0)\n",
    "        return arr\n",
    "    \n",
    "    def get_segmentation(self, data: np.ndarray)->np.ndarray:\n",
    "        \"\"\"Segmentation modelを使って、各臓器のマスクを作成.\n",
    "        Args:\n",
    "            data: (Z, H, W).\n",
    "        Returns:\n",
    "            mask: (organs, z, h, w) binarized.\"\"\"\n",
    "        seg_iterator = self.pseudo_iterator(self.CFG_SEG, data)\n",
    "        seg_result = seg_evaluate(self.CFG_SEG, self.seg_models, seg_iterator)\n",
    "        pred = seg_result[\"pred\"]\n",
    "        pred = (pred > 0.5).astype(np.uint8)\n",
    "        return pred\n",
    "    \n",
    "    def be_prediction(self, data: np.ndarray)-> np.ndarray:\n",
    "        \"\"\"bowel_injury及びextravasation_injuryの予測を行う.\n",
    "        Args:\n",
    "            data: (Z, H, W).\n",
    "        Returns:\n",
    "            np.ndarray: (len(data), len(['bowel_injury', 'extravasation_injury'])).\n",
    "        \"\"\"\n",
    "        be_iterator = self.pseudo_iterator(self.CFG_BE, data)\n",
    "        be_result = cls_evaluate(self.CFG_BE, self.be_models, be_iterator)\n",
    "        pred = be_result[\"pred\"]\n",
    "        return pred\n",
    "\n",
    "    def pseudo_iterator(self, CFG: Any, images: np.ndarray)-> tuple:\n",
    "        \"\"\"evaluation iterator.\n",
    "        Args:\n",
    "            CFG: config.\n",
    "            images: (batch dim, H, W) or (batch dim, Z, H, W).\n",
    "        \"\"\"\n",
    "        batch = CFG.batch_size\n",
    "        for i in range(0, len(images), batch):\n",
    "            yield images[i : i + batch]\n",
    "\n",
    "    def convert_submission_format(self, pred: dict)->dict:\n",
    "        \"\"\"提出形式に変換する.\"\"\"\n",
    "        converted = dict()\n",
    "        for idx, organ in organ_index_dict_inv.items():\n",
    "            if idx == 3:\n",
    "                continue\n",
    "            for idx, grade in enumerate(['healthy', 'low', 'high']):\n",
    "                converted[f'{organ}_{grade}'] = pred[organ][idx]\n",
    "        for idx, label in label_index_dict_inv.items():\n",
    "            converted[f'{label}_healthy'] = 1 - pred[label]\n",
    "            converted[f'{label}_injury'] = pred[label]\n",
    "\n",
    "        converted['patient_id'] = pred['pid']\n",
    "        return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_instance = Inference()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
