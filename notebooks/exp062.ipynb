{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp062   \n",
    "[Notion](https://www.notion.so/exp062-d96b75e9813c48799c0d5e6c9fa28cfd?pvs=4)    \n",
    "lsk: exp058, be: exp026を用いた場合のcvを算出する  \n",
    "Copy from: exp032 <- exp028.ipynb <- exp025.ipynb <- exp021.ipynb <- exp018.ipynb <- exp012.ipynb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import defaultdict\n",
    "from typing import Tuple, Any, Dict, Optional\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# リポジトリtopに移動\n",
    "while os.path.basename(os.getcwd()) != 'rsna-2023':\n",
    "    os.chdir('../')\n",
    "    if os.getcwd() == '/':\n",
    "        raise Exception('Could not find project root directory.')\n",
    "    \n",
    "from src.data_io import load_dicom_series\n",
    "from src.segmentation.dataset import TestDataset as SegTestDataset\n",
    "from src.segmentation.model import load_models as seg_load_models\n",
    "from src.segmentation.trainer import inference as seg_inference\n",
    "from src.classification.dataset import TestDatasetBowelExtra, TestDatasetSolidOrgans\n",
    "from src.image_processing import apply_preprocess, crop_organ, kidney_split, resize_volume, apply_postprocess, kidney_specific, resize_3d, resize_1d\n",
    "from src.classification.model import load_models as cls_load_models\n",
    "from src.classification.trainer import inference as cls_inference\n",
    "from src.metrics import score, create_training_solution, normalize_probabilities_to_one\n",
    "from src.classification.dataset import load_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG_INF:\n",
    "    exp_name = 'exp_062'\n",
    "    # evaluation時：'train', submission時：'test'\n",
    "    phase = 'train'\n",
    "    base_dir = 'data/rsna-2023-abdominal-trauma-detection'\n",
    "    image_dir = f'data/rsna-2023-abdominal-trauma-detection/{phase}_images'\n",
    "    # dataframeはこのconfigにもたせ、phaseで対応できるようにする.\n",
    "    if phase == 'train':\n",
    "        df = pd.read_csv(os.path.join(base_dir, 'train.csv'))\n",
    "    elif phase == 'test':\n",
    "        df = pd.read_csv(os.path.join(base_dir, 'sample_submission.csv'))\n",
    "    df_series_meta = pd.read_csv(os.path.join(base_dir, f'{phase}_series_meta.csv'))\n",
    "    image_size = (512, 512)\n",
    "    # sample submissionで極端にスライス数が少ない場合があるため対応.\n",
    "    min_slices = 10\n",
    "    # 推論時間制限のため\n",
    "    max_slices = 500\n",
    "    max_series = 2\n",
    "    model_save_dir = \"outputs\"\n",
    "    lsk_model_mode = 'final'\n",
    "    be_model_mode = 'final'\n",
    "\n",
    "class CFG_LSK:\n",
    "    exp_name = 'exp_058'\n",
    "    # model config\n",
    "    # timm backbone\n",
    "    backbone = 'efficientnet-b4'\n",
    "    n_ch = 1\n",
    "    expand_ch_dim = True\n",
    "    # n_class: healthy, low, high\n",
    "    n_class = 3\n",
    "    # hyper params\n",
    "    wl = 0\n",
    "    ww = 1000\n",
    "    init_lr = 5e-4\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-4\n",
    "    image_size = (128, 128, 160)\n",
    "    batch_size = 32\n",
    "    amp = False\n",
    "    eps = 1e-8\n",
    "    n_epoch = 24\n",
    "    pretrain = True\n",
    "    freeze_epochs = 0\n",
    "    noaug_epochs = 1\n",
    "    # fold config\n",
    "    n_fold = 6\n",
    "    include_evaluation = False\n",
    "    train_folds = 1\n",
    "    # path\n",
    "    image_dir = \"data/dataset002\"\n",
    "    model_save_dir = \"outputs\"\n",
    "    # other config\n",
    "    seed = 42\n",
    "    num_workers = 4\n",
    "    num_gpus = 2\n",
    "    progress_bar = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    class_weight=torch.tensor([1.0, 2.0, 4.0]).to(device)\n",
    "\n",
    "class CFG_BE:\n",
    "    exp_name = 'exp_026'\n",
    "    # model config\n",
    "    # timm backbone\n",
    "    backbone = 'efficientnet_b4'\n",
    "    # n_ch: z軸方向のスライス数\n",
    "    n_ch = 5\n",
    "    expand_ch_dim = False\n",
    "    # n_class: bowel_injury, extravasation\n",
    "    # sample weighted: 4class\n",
    "    n_class = 4\n",
    "    label_smoothing = None #Optional(float)\n",
    "    # hyper params\n",
    "    ww = 1000\n",
    "    wl = 0\n",
    "    init_lr = 5e-5\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-4\n",
    "    image_size = (512, 512)\n",
    "    batch_size = 64\n",
    "    amp = True\n",
    "    eps = 1e-7\n",
    "    n_epoch = 18\n",
    "    iteration_per_epoch = 100\n",
    "    pretrain = True\n",
    "    freeze_epochs = 1\n",
    "    noaug_epochs = 2\n",
    "    # fold config\n",
    "    n_fold = 6\n",
    "    include_evaluation = False\n",
    "    train_folds = 1\n",
    "    # path\n",
    "    image_dir = \"data/dataset001\"\n",
    "    model_save_dir = \"outputs\"\n",
    "    # other config\n",
    "    seed = 42\n",
    "    num_workers = 4\n",
    "    num_gpus = 2\n",
    "    progress_bar = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # b_healty, b_injury, e_healty, e_injury\n",
    "    class_weight=torch.tensor([1.0, 2.0, 1.0, 6.0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organs dict (for SEG and LSK models)\n",
    "organ_index_dict_inv = {\n",
    "    0: 'liver',\n",
    "    1: 'spleen',\n",
    "    2: 'kidney',\n",
    "    3: 'bowel'\n",
    "}\n",
    "organ_index_dict = {v: k for k, v in organ_index_dict_inv.items()}\n",
    "\n",
    "# labels dict (for BE models)\n",
    "label_index_dict_inv = {\n",
    "    0: 'bowel',\n",
    "    1: 'extravasation'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_series_from_dataset(dir_: str, max_slices: Optional[int]=None)-> np.ndarray:\n",
    "    \"\"\"seriesを読み込む.\"\"\"\n",
    "    path_list = os.listdir(dir_)\n",
    "    path_list = [[int(path.replace(\".npy\",\"\")), path] for path in path_list]\n",
    "    path_list.sort()\n",
    "    path_list = [path[1] for path in path_list]\n",
    "    if max_slices is not None:\n",
    "        step = (len(path_list) + max_slices - 1) // max_slices\n",
    "        path_list = path_list[::step]\n",
    "    arr = []\n",
    "    for path in path_list:\n",
    "        arr.append(np.load(os.path.join(dir_, path)))\n",
    "    return np.array(arr)\n",
    "\n",
    "def load_image(path: str) -> np.ndarray:\n",
    "    \"\"\"画像の読み込み.\n",
    "    Args:\n",
    "        path (str): 画像のパス.\n",
    "    Returns:\n",
    "        numpy.ndarray: 画像.\n",
    "    Note:\n",
    "        現在読み込む画像の形式は.png, .npy, .npzのみ対応.\n",
    "        cv2.IMREAD_UNCHANGED: 16bit画像やアルファチャンネルを考慮した読み込み.\n",
    "    \"\"\"\n",
    "    if path.endswith(\".png\"):\n",
    "        image = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    elif path.endswith(\".npy\"):\n",
    "        image = np.load(path)\n",
    "    elif path.endswith(\".npz\"):\n",
    "        image = np.load(path)[\"arr_0\"]\n",
    "    else:\n",
    "        raise Exception(f\"unexpected image format: {path}\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    \"\"\"推論パイプライン.\"\"\"\n",
    "    def __init__(self,CFG_INF: Any, CFG_LSK: Any, CFG_BE: Any):\n",
    "        self.CFG_INF = CFG_INF\n",
    "        self.CFG_LSK = CFG_LSK\n",
    "        self.CFG_BE = CFG_BE\n",
    "        \n",
    "        self.lsk_models = cls_load_models(CFG_LSK, mode=self.CFG_INF.lsk_model_mode)\n",
    "        self.be_models = cls_load_models(CFG_BE, mode=self.CFG_INF.be_model_mode, framework=\"timm\")\n",
    "    \n",
    "    def __call__(self, pid: int) -> tuple:\n",
    "        \"\"\"inference process.\n",
    "        1. load images from dicom files.\n",
    "        2. create segmentation masks.\n",
    "        3. create liver, spleen, kidney volumes.\n",
    "        4. inference lsk models.\n",
    "        5. inference be models.\n",
    "        Args:\n",
    "            pid (int): patient id.\n",
    "        Return example:\n",
    "            dict: {\n",
    "            'pid': 0,\n",
    "            'bowel_healthy': 0.0,\n",
    "            'bowel_injury': 0.0,\n",
    "            'extravasation_healthy': 0.0,\n",
    "            'extravasation_injury': 0.0,\n",
    "            'kidney_healthy': 0.0,\n",
    "            'kidney_low': 0.0,\n",
    "            'kidney_high': 0.0,\n",
    "            'liver_healthy': 0.0,\n",
    "            'liver_low': 0.0,\n",
    "            'liver_high': 0.0,\n",
    "            'spleen_healthy': 0.0,\n",
    "            'spleen_low': 0.0,\n",
    "            'spleen_high': 0.0\n",
    "            }\n",
    "        Note:\n",
    "            - １症例に複数シリーズ存在する場合、各シリーズに対して推論を行い、全予測結果の最大値を採用する.\n",
    "            - 推論時間的に厳しければ、最初のシリーズのみを採用するなど検討.\n",
    "        \"\"\"\n",
    "        df_study = self.CFG_INF.df_series_meta[self.CFG_INF.df_series_meta['patient_id']==pid].reset_index(drop=True)\n",
    "        # df_study内のそれぞれのシリーズを取得して、画像枚数に対して降順にソート.\n",
    "        df_study = self.get_slices_and_sort(df_study)\n",
    "        preds = defaultdict(list)\n",
    "        for sid in df_study['series_id'].to_list()[:self.CFG_INF.max_series]:\n",
    "            data = self.load_data(pid, sid)\n",
    "            if data is None:\n",
    "                continue\n",
    "            lsk_preds = self.lsk_prediction(pid, sid)\n",
    "            be_preds = self.be_prediction(data)\n",
    "            for idx, organ in organ_index_dict_inv.items():\n",
    "                if idx == 3:\n",
    "                    continue\n",
    "                preds[organ].append(lsk_preds[idx])\n",
    "            for idx, label in label_index_dict_inv.items():\n",
    "                pred = np.array([be_preds[idx]])\n",
    "                preds[label].append(pred)\n",
    "\n",
    "        ret = {'patient_id': pid}\n",
    "        for k,v in preds.items():\n",
    "            v = np.array(v)\n",
    "            ret[k] = np.max(v, axis=0)\n",
    "        ret = self.convert_submission_format(ret)\n",
    "        return ret\n",
    "\n",
    "    def load_data(self, pid: int, sid: int)-> np.ndarray:\n",
    "        \"\"\"dicomから画像を読み込む.\n",
    "        Args:\n",
    "            pid (int): patient id.\n",
    "            sid (int): series id.\n",
    "        Returns:\n",
    "            np.ndarray: (Z, H, W) normalized CT series.\n",
    "        Note:\n",
    "            - preprocessは全モデル共通なので、ここで行う.\n",
    "            - H, Wはすべてself.CFG_INF.image_sizeにresizeされる.\n",
    "        \"\"\"\n",
    "        series_path = os.path.join(self.CFG_BE.image_dir, 'train_images', str(pid), str(sid))\n",
    "        # sample submissionでこういう例が存在する.\n",
    "        if not os.path.exists(series_path):  \n",
    "            return None\n",
    "        image_arr = load_series_from_dataset(series_path, self.CFG_INF.max_slices)\n",
    "        image_arr = apply_preprocess(image_arr, resize=self.CFG_INF.image_size)\n",
    "        # sample submission対応\n",
    "        if len(image_arr) < self.CFG_INF.min_slices:\n",
    "            image_arr = resize_1d(image_arr, self.CFG_INF.min_slices, axis=0)\n",
    "        return image_arr\n",
    "    \n",
    "    def get_slices_and_sort(self, df_study: pd.DataFrame)-> pd.DataFrame:\n",
    "        \"\"\"シリーズのスライス数を取得して、スライス数に対して降順にソートする.\n",
    "        Args:\n",
    "            df_study (pd.DataFrame): series meta dataframe.\n",
    "        Returns:\n",
    "            pd.DataFrame: sorted series meta dataframe.\n",
    "        \"\"\"\n",
    "        pid = df_study['patient_id'][0]\n",
    "        df_study['n_slices'] = 0\n",
    "        for i in range(len(df_study)):\n",
    "            sid = df_study['series_id'][i]\n",
    "            series_path = os.path.join(self.CFG_INF.image_dir, str(pid), str(sid))\n",
    "            if os.path.exists(series_path):\n",
    "                df_study['n_slices'][i] = len(os.listdir(series_path))\n",
    "        df_study = df_study.sort_values(by='n_slices', ascending=False)\n",
    "        return df_study\n",
    "    \n",
    "    def lsk_prediction(self, pid: int, sid: int)-> np.ndarray:\n",
    "        \"\"\"liver, spleen, kidneyの予測値を返す.\n",
    "        Args:\n",
    "            pid: patient id\n",
    "            sid: series id\n",
    "        Returns:\n",
    "            np.ndarray: (organs, grades).\n",
    "        \"\"\"\n",
    "        volumes = self.get_lsk_volumes(pid, sid) # (organs, z, h, w)\n",
    "        volumes = apply_preprocess(volumes, wl=self.CFG_LSK.wl, ww=self.CFG_LSK.ww)\n",
    "        lsk_iterator = self.pseudo_iterator(self.CFG_LSK, volumes)\n",
    "        pred = cls_inference(self.CFG_LSK, self.lsk_models, lsk_iterator)\n",
    "        return pred\n",
    "\n",
    "    def get_lsk_volumes(self, pid: int, sid: int)->Dict[str, np.ndarray]:\n",
    "        \"\"\"Segmentationからliver, spleen, kidneyのvolume dataを作成.\n",
    "        Args:\n",
    "            pid: patient id\n",
    "            sid: series id\n",
    "        Returns:\n",
    "            np.ndarray: (organs, z, h, w).\n",
    "        Note:\n",
    "            - organsはliver, spleen, kidneyの順番.\n",
    "            - この関数内でCFG.LSK.image_sizeのreshapeまで行う.\n",
    "            - 腎臓は左右を分離してからくっつけ直すという特殊な処理が必要.\n",
    "        \"\"\"\n",
    "        arr = []\n",
    "        for idx, organ in organ_index_dict_inv.items():\n",
    "            if idx == 3:\n",
    "                continue\n",
    "            path = os.path.join(self.CFG_LSK.image_dir, str(pid), str(sid), f\"{organ}.npy\")\n",
    "            if organ == \"kidney\":\n",
    "                # 解剖学的な左右を、画像上の左右に置き換えて読み込み\n",
    "                l, r = (\n",
    "                    path.replace(\"kidney.npy\", \"kidney_r.npy\"),\n",
    "                    path.replace(\"kidney.npy\", \"kidney_l.npy\"),\n",
    "                )\n",
    "                if os.path.exists(l):\n",
    "                    l = load_image(l)\n",
    "                else:\n",
    "                    l = np.zeros(self.CFG_LSK.image_size)\n",
    "                if os.path.exists(r):\n",
    "                    r = load_image(r)\n",
    "                else:\n",
    "                    r = np.zeros(self.CFG_LSK.image_size)\n",
    "                img_cropped = kidney_specific(self.CFG_LSK, l, r)\n",
    "            else:\n",
    "                organ_segment = load_image(path)\n",
    "                img_cropped = resize_3d(organ_segment, self.CFG_LSK.image_size)\n",
    "                \n",
    "            arr.append(img_cropped)\n",
    "        arr = np.stack(arr, axis=0)\n",
    "        return arr\n",
    "    \n",
    "    def be_prediction(self, data: np.ndarray)-> np.ndarray:\n",
    "        \"\"\"bowel_injury及びextravasation_injuryの予測を行う.\n",
    "        Args:\n",
    "            data: (Z, H, W).\n",
    "        Returns:\n",
    "            np.ndarray: [bowel_injury_pred, extravasation_injury_pred].\n",
    "            example: [0.1, 0.9].\n",
    "        \"\"\"\n",
    "        be_iterator = self.pseudo_iterator(self.CFG_BE, data)\n",
    "        pred = cls_inference(self.CFG_BE, self.be_models, be_iterator)\n",
    "        pred = self.be_prediction_postprocess(pred)\n",
    "        return pred\n",
    "    \n",
    "    def be_prediction_postprocess(self, pred: np.ndarray)-> np.ndarray:\n",
    "        \"\"\"スライスごとの予測をシリーズの予測に変換する.\n",
    "        Args:\n",
    "            pred: (len(data),['bowel_injury', 'extravasation_injury']).\n",
    "        Returns:\n",
    "            np.ndarray: ['bowel_injury', 'extravasation_injury'].\n",
    "        Note:\n",
    "            - 予測値の最大値から外れ値を考慮した2%percentileを採用する.\n",
    "        \"\"\"\n",
    "        if self.CFG_BE.n_class == 1:\n",
    "            bowel = np.zeros_like(pred[:, 0])\n",
    "            extravasation = pred[:, 0]\n",
    "        elif self.CFG_BE.n_class == 2:\n",
    "            bowel = pred[:, 0]\n",
    "            extravasation = pred[:, 1]\n",
    "        elif self.CFG_BE.n_class == 4:\n",
    "            bowel = normalize_probabilities_to_one(pred[:, :2])\n",
    "            extravasation = normalize_probabilities_to_one(pred[:, 2:])\n",
    "            bowel = bowel[:, 1]\n",
    "            extravasation = extravasation[:, 1]\n",
    "        \n",
    "        p = 98\n",
    "        bowel = np.percentile(bowel, p)\n",
    "        extravasation = np.percentile(extravasation, p)\n",
    "        return np.array([bowel, extravasation])\n",
    "\n",
    "    def pseudo_iterator(self, CFG: Any, images: np.ndarray)-> tuple:\n",
    "        \"\"\"evaluation iterator.\n",
    "        Args:\n",
    "            CFG: config.\n",
    "            images: (batch dim, H, W) or (batch dim, Z, H, W).\n",
    "        \"\"\"\n",
    "        batch = CFG.batch_size\n",
    "        length = len(images)\n",
    "        arr = []\n",
    "        if not CFG.expand_ch_dim:\n",
    "            images = self.add_dummy_array(CFG, images)\n",
    "        for i in range(length):\n",
    "            if CFG.expand_ch_dim:\n",
    "                img = images[i]\n",
    "                img = img[np.newaxis, ...]\n",
    "            else:\n",
    "                img = images[i:i+CFG.n_ch]\n",
    "            arr.append(img)\n",
    "            if i != 0 and (i%batch==0 or i == length-1):\n",
    "                arr = np.stack(arr, axis=0)\n",
    "                arr = torch.from_numpy(arr.astype(arr.dtype, copy=False))\n",
    "                yield arr\n",
    "                arr = []\n",
    "\n",
    "    def add_dummy_array(self, CFG: Any, images: np.ndarray)-> np.ndarray:\n",
    "        \"\"\"chが複数ある場合に、事前に0配列を追加しておく.\"\"\"\n",
    "        add_ch = CFG.n_ch//2\n",
    "        arr = []\n",
    "        img = np.zeros_like(images[0])\n",
    "        for i in range(add_ch):\n",
    "            arr.append(img)\n",
    "        arr.extend(images)\n",
    "        for i in range(add_ch):\n",
    "            arr.append(img)\n",
    "        arr = np.stack(arr, axis=0)\n",
    "        return arr\n",
    "    \n",
    "    def convert_submission_format(self, pred: dict)->dict:\n",
    "        \"\"\"提出形式に変換する.\"\"\"\n",
    "        converted = dict()\n",
    "        for idx, organ in organ_index_dict_inv.items():\n",
    "            if idx == 3:\n",
    "                continue\n",
    "            for idx, grade in enumerate(['healthy', 'low', 'high']):\n",
    "                converted[f'{organ}_{grade}'] = pred[organ][idx]\n",
    "        for idx, label in label_index_dict_inv.items():\n",
    "            converted[f'{label}_healthy'] = 1 - pred[label][0]\n",
    "            converted[f'{label}_injury'] = pred[label][0]\n",
    "\n",
    "        converted['patient_id'] = pred['patient_id']\n",
    "        return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solid_organ = load_df(CFG_LSK)\n",
    "# fold 0のpatient_idを取得\n",
    "pids = df_solid_organ[df_solid_organ[\"fold\"] == 0][\"patient_id\"].unique()\n",
    "df_all = pd.read_csv(os.path.join(CFG_INF.base_dir, 'train.csv'))\n",
    "train_pids = df_solid_organ[df_solid_organ[\"fold\"] != 0][\"patient_id\"].unique()\n",
    "valid_pids = df_solid_organ[df_solid_organ[\"fold\"] == 0][\"patient_id\"].unique()\n",
    "df_train = df_all[df_all[\"patient_id\"].isin(train_pids)].reset_index(drop=True)\n",
    "df_valid = df_all[df_all[\"patient_id\"].isin(valid_pids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_instance = Inference(CFG_INF, CFG_LSK, CFG_BE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [27:49<00:00,  3.18s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for pid in tqdm(df_valid['patient_id'].to_list()):\n",
    "    result = inference_instance(pid)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# resultsを保存\n",
    "dir_ = os.path.join(CFG_INF.model_save_dir, CFG_INF.exp_name)\n",
    "os.makedirs(dir_, exist_ok=True)\n",
    "path = os.path.join(dir_, \"results_seg004_lsk062_be026.pkl\")\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "# resultsを読み込み\n",
    "# with open(path, 'rb') as f:\n",
    "#    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(results)\n",
    "order = CFG_INF.df.columns.tolist()\n",
    "if \"any_injury\" in order:\n",
    "    order.remove(\"any_injury\")\n",
    "submission = submission[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_hack(df:pd.DataFrame)->pd.DataFrame:\n",
    "    \"\"\"bowel, liver, spleen, kidney.いずれかが高い予測値を持つとき、extravasationも合併している確率が高い.\"\"\"\n",
    "    cols = [\"liver_low\", \"liver_high\", \"spleen_low\", \"spleen_high\", \"kidney_low\", \"kidney_high\"]\n",
    "    # \"extravasation_injury\", \"bowel_injury\", \n",
    "    df[\"extravasation_injury\"] = df[cols].max(axis=1)\n",
    "    df[\"extravasation_healthy\"] = 1 - df[\"extravasation_injury\"]\n",
    "    return df\n",
    "# submission = metric_hack(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def min_scaling(submission: pd.DataFrame)->pd.DataFrame:\\n    cols = [\"bowel_injury\", \"extravasation_injury\", \"kidney_low\", \"kidney_high\", \"liver_low\", \"liver_high\", \"spleen_low\", \"spleen_high\"]\\n    for col in cols:\\n        train_mean = df_train[col].mean()\\n        submission[col] = submission[col].apply(lambda x: max(x, train_mean))\\n    return submission\\nsubmission = min_scaling(submission)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def min_scaling(submission: pd.DataFrame)->pd.DataFrame:\n",
    "    cols = [\"bowel_injury\", \"extravasation_injury\", \"kidney_low\", \"kidney_high\", \"liver_low\", \"liver_high\", \"spleen_low\", \"spleen_high\"]\n",
    "    for col in cols:\n",
    "        train_mean = df_train[col].mean()\n",
    "        submission[col] = submission[col].apply(lambda x: max(x, train_mean))\n",
    "    return submission\n",
    "submission = min_scaling(submission)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bowel_healthy</th>\n",
       "      <th>bowel_injury</th>\n",
       "      <th>extravasation_healthy</th>\n",
       "      <th>extravasation_injury</th>\n",
       "      <th>kidney_healthy</th>\n",
       "      <th>kidney_low</th>\n",
       "      <th>kidney_high</th>\n",
       "      <th>liver_healthy</th>\n",
       "      <th>liver_low</th>\n",
       "      <th>liver_high</th>\n",
       "      <th>spleen_healthy</th>\n",
       "      <th>spleen_low</th>\n",
       "      <th>spleen_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10007</td>\n",
       "      <td>0.816518</td>\n",
       "      <td>0.183482</td>\n",
       "      <td>0.947678</td>\n",
       "      <td>0.052322</td>\n",
       "      <td>0.954574</td>\n",
       "      <td>0.038951</td>\n",
       "      <td>0.006352</td>\n",
       "      <td>0.933550</td>\n",
       "      <td>0.057598</td>\n",
       "      <td>0.012507</td>\n",
       "      <td>0.875140</td>\n",
       "      <td>0.090427</td>\n",
       "      <td>0.033178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10205</td>\n",
       "      <td>0.779929</td>\n",
       "      <td>0.220071</td>\n",
       "      <td>0.946795</td>\n",
       "      <td>0.053205</td>\n",
       "      <td>0.950645</td>\n",
       "      <td>0.043412</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.981073</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.974444</td>\n",
       "      <td>0.024062</td>\n",
       "      <td>0.002744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10275</td>\n",
       "      <td>0.956565</td>\n",
       "      <td>0.043435</td>\n",
       "      <td>0.965257</td>\n",
       "      <td>0.034743</td>\n",
       "      <td>0.859022</td>\n",
       "      <td>0.116988</td>\n",
       "      <td>0.062943</td>\n",
       "      <td>0.982928</td>\n",
       "      <td>0.021596</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.977679</td>\n",
       "      <td>0.094162</td>\n",
       "      <td>0.033515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10430</td>\n",
       "      <td>0.956799</td>\n",
       "      <td>0.043201</td>\n",
       "      <td>0.844909</td>\n",
       "      <td>0.155091</td>\n",
       "      <td>0.947168</td>\n",
       "      <td>0.059517</td>\n",
       "      <td>0.013351</td>\n",
       "      <td>0.891898</td>\n",
       "      <td>0.170454</td>\n",
       "      <td>0.175278</td>\n",
       "      <td>0.945172</td>\n",
       "      <td>0.063931</td>\n",
       "      <td>0.015326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10494</td>\n",
       "      <td>0.816477</td>\n",
       "      <td>0.183523</td>\n",
       "      <td>0.916104</td>\n",
       "      <td>0.083896</td>\n",
       "      <td>0.473052</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.391207</td>\n",
       "      <td>0.935601</td>\n",
       "      <td>0.054307</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>0.964685</td>\n",
       "      <td>0.031990</td>\n",
       "      <td>0.004423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>9537</td>\n",
       "      <td>0.917280</td>\n",
       "      <td>0.082720</td>\n",
       "      <td>0.993776</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>0.978687</td>\n",
       "      <td>0.020146</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.966626</td>\n",
       "      <td>0.030505</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>0.979633</td>\n",
       "      <td>0.017989</td>\n",
       "      <td>0.001791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>96</td>\n",
       "      <td>0.877808</td>\n",
       "      <td>0.122192</td>\n",
       "      <td>0.984195</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.962432</td>\n",
       "      <td>0.035130</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.975933</td>\n",
       "      <td>0.021711</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.949980</td>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.007465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>9620</td>\n",
       "      <td>0.929224</td>\n",
       "      <td>0.070776</td>\n",
       "      <td>0.950181</td>\n",
       "      <td>0.049819</td>\n",
       "      <td>0.956405</td>\n",
       "      <td>0.038967</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>0.957148</td>\n",
       "      <td>0.038276</td>\n",
       "      <td>0.005905</td>\n",
       "      <td>0.962343</td>\n",
       "      <td>0.034423</td>\n",
       "      <td>0.004911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>9835</td>\n",
       "      <td>0.951448</td>\n",
       "      <td>0.048552</td>\n",
       "      <td>0.971621</td>\n",
       "      <td>0.028379</td>\n",
       "      <td>0.980681</td>\n",
       "      <td>0.017906</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.668040</td>\n",
       "      <td>0.175254</td>\n",
       "      <td>0.209893</td>\n",
       "      <td>0.924891</td>\n",
       "      <td>0.065130</td>\n",
       "      <td>0.016145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>9980</td>\n",
       "      <td>0.771483</td>\n",
       "      <td>0.228517</td>\n",
       "      <td>0.974225</td>\n",
       "      <td>0.025775</td>\n",
       "      <td>0.962716</td>\n",
       "      <td>0.050287</td>\n",
       "      <td>0.009239</td>\n",
       "      <td>0.934008</td>\n",
       "      <td>0.058118</td>\n",
       "      <td>0.012052</td>\n",
       "      <td>0.340154</td>\n",
       "      <td>0.232549</td>\n",
       "      <td>0.562331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id  bowel_healthy  bowel_injury  extravasation_healthy  \\\n",
       "0         10007       0.816518      0.183482               0.947678   \n",
       "1         10205       0.779929      0.220071               0.946795   \n",
       "2         10275       0.956565      0.043435               0.965257   \n",
       "3         10430       0.956799      0.043201               0.844909   \n",
       "4         10494       0.816477      0.183523               0.916104   \n",
       "..          ...            ...           ...                    ...   \n",
       "520        9537       0.917280      0.082720               0.993776   \n",
       "521          96       0.877808      0.122192               0.984195   \n",
       "522        9620       0.929224      0.070776               0.950181   \n",
       "523        9835       0.951448      0.048552               0.971621   \n",
       "524        9980       0.771483      0.228517               0.974225   \n",
       "\n",
       "     extravasation_injury  kidney_healthy  kidney_low  kidney_high  \\\n",
       "0                0.052322        0.954574    0.038951     0.006352   \n",
       "1                0.053205        0.950645    0.043412     0.007333   \n",
       "2                0.034743        0.859022    0.116988     0.062943   \n",
       "3                0.155091        0.947168    0.059517     0.013351   \n",
       "4                0.083896        0.473052    0.221400     0.391207   \n",
       "..                    ...             ...         ...          ...   \n",
       "520              0.006224        0.978687    0.020146     0.001995   \n",
       "521              0.015805        0.962432    0.035130     0.004900   \n",
       "522              0.049819        0.956405    0.038967     0.006041   \n",
       "523              0.028379        0.980681    0.017906     0.002260   \n",
       "524              0.025775        0.962716    0.050287     0.009239   \n",
       "\n",
       "     liver_healthy  liver_low  liver_high  spleen_healthy  spleen_low  \\\n",
       "0         0.933550   0.057598    0.012507        0.875140    0.090427   \n",
       "1         0.981073   0.018001    0.001689        0.974444    0.024062   \n",
       "2         0.982928   0.021596    0.002275        0.977679    0.094162   \n",
       "3         0.891898   0.170454    0.175278        0.945172    0.063931   \n",
       "4         0.935601   0.054307    0.011161        0.964685    0.031990   \n",
       "..             ...        ...         ...             ...         ...   \n",
       "520       0.966626   0.030505    0.003963        0.979633    0.017989   \n",
       "521       0.975933   0.021711    0.002337        0.949980    0.042339   \n",
       "522       0.957148   0.038276    0.005905        0.962343    0.034423   \n",
       "523       0.668040   0.175254    0.209893        0.924891    0.065130   \n",
       "524       0.934008   0.058118    0.012052        0.340154    0.232549   \n",
       "\n",
       "     spleen_high  \n",
       "0       0.033178  \n",
       "1       0.002744  \n",
       "2       0.033515  \n",
       "3       0.015326  \n",
       "4       0.004423  \n",
       "..           ...  \n",
       "520     0.001791  \n",
       "521     0.007465  \n",
       "522     0.004911  \n",
       "523     0.016145  \n",
       "524     0.562331  \n",
       "\n",
       "[525 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bowel: 0.1935\n",
      "extravasation: 0.8347\n",
      "kidney: 0.4012\n",
      "liver: 0.5376\n",
      "spleen: 0.5697\n",
      "any_injury: 0.9692\n",
      "mean: 0.5843\n",
      "Training score without scaling: 0.5843\n"
     ]
    }
   ],
   "source": [
    "# add weight\n",
    "solution_train = create_training_solution(df_valid)\n",
    "\n",
    "no_scale_score = score(solution_train.copy(),submission.copy(),'patient_id')\n",
    "print(f'Training score without scaling: {no_scale_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bowel: 0.2804\n",
      "extravasation: 0.5995\n",
      "kidney: 0.3822\n",
      "liver: 0.5423\n",
      "spleen: 0.5432\n",
      "any_injury: 0.6361\n",
      "mean: 0.4973\n",
      "Training score with weight scaling: 0.4973\n"
     ]
    }
   ],
   "source": [
    "# Group by different sample weights\n",
    "scale_by_2 = ['bowel_injury', 'kidney_low','liver_low','spleen_low']\n",
    "scale_by_4 = ['kidney_high','liver_high','spleen_high']\n",
    "scale_by_6 = ['extravasation_injury']\n",
    "\n",
    "# Scale factors based on described metric \n",
    "sf_2 = 2\n",
    "sf_4 = 4\n",
    "sf_6 = 6\n",
    "\n",
    "# Reset the prediction\n",
    "y_pred = submission.copy()\n",
    "\n",
    "# Scale each target \n",
    "y_pred[scale_by_2] *=sf_2\n",
    "y_pred[scale_by_4] *=sf_4\n",
    "y_pred[scale_by_6] *=sf_6\n",
    "\n",
    "weight_scale_score = score(solution_train.copy(),y_pred.copy(),'patient_id')\n",
    "print(f'Training score with weight scaling: {weight_scale_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
