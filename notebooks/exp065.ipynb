{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp065  \n",
    "[Notion](https://www.notion.so/exp065-23e8532369184fe7950e2936de90915c?pvs=4)  \n",
    "3D-CNNによる固形臓器(Liver, Spleen, Kidney)損傷の検出のために、セグメンテーションした臓器のスライス位置のdataframeを作成し保存.  \n",
    "copy from: exp005  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from typing import Any, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import animation, rc\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams['animation.embed_limit'] = 70\n",
    "\n",
    "# リポジトリtopに移動\n",
    "while os.path.basename(os.getcwd()) != 'rsna-2023':\n",
    "    os.chdir('../')\n",
    "    if os.getcwd() == '/':\n",
    "        raise Exception('Could not find project root directory.')\n",
    "    \n",
    "from src.segmentation.dataset import TestDataset, load_df\n",
    "from src.image_processing import windowing\n",
    "from src.visualization import apply_colormap_to_multilabel_images, animate, print_injury\n",
    "from src.segmentation.model import load_models\n",
    "from src.segmentation.trainer import evaluate\n",
    "from src.image_processing import apply_preprocess\n",
    "from src.segmentation.model import load_models as seg_load_models\n",
    "from src.segmentation.trainer import inference as seg_inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    exp_name = 'exp_004'\n",
    "    # model config\n",
    "    backbone = 'efficientnet-b3'\n",
    "    n_ch = 1\n",
    "    n_class = 4 # 学習時は腎臓の左右を区別しないので、5->4\n",
    "    # hyper params\n",
    "    expand_ch_dim = False\n",
    "    wl = 0\n",
    "    ww = 400\n",
    "    init_lr = 1e-3\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-4\n",
    "    image_size = (512, 512)\n",
    "    batch_size = 32\n",
    "    amp = True\n",
    "    n_epoch = 20\n",
    "    iteration_per_epoch = 200\n",
    "    pretrain = True\n",
    "    freeze_epochs = 1\n",
    "    noaug_epochs = 1\n",
    "    # fold config\n",
    "    n_fold = 6\n",
    "    include_evaluation = False\n",
    "    train_folds = 1\n",
    "    # path\n",
    "    image_dir = \"data/dataset001/train_images\"\n",
    "    mask_dir = \"data/dataset001/segmentations\"\n",
    "    model_save_dir = \"outputs\"\n",
    "    # other config\n",
    "    seed = 42\n",
    "    num_workers = 0\n",
    "    num_gpus = 2\n",
    "    progress_bar = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/rsna-2023-abdominal-trauma-detection/train.csv')\n",
    "df_train_image_level = pd.read_csv('data/rsna-2023-abdominal-trauma-detection/image_level_labels.csv')\n",
    "df_train_series_meta = pd.read_csv('data/rsna-2023-abdominal-trauma-detection/train_series_meta.csv')\n",
    "base_dir = \"data/rsna-2023-abdominal-trauma-detection\"\n",
    "dataset_dir = \"data/dataset002\"\n",
    "\n",
    "# get label correspondences\n",
    "organ_index_dict_inv = {\n",
    "    0: 'liver',\n",
    "    1: 'spleen',\n",
    "    2: 'kidney',\n",
    "    3: 'bowel'\n",
    "}\n",
    "organ_index_dict = {v: k for k, v in organ_index_dict_inv.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe():\n",
    "    \"\"\"データセットのDataFrameを作成する.\n",
    "    データセットによって内容を書き換える必要あり.\n",
    "    \"\"\"\n",
    "    # df_train_series_metaをベースに、データフレームを構築.\n",
    "    image_paths = []\n",
    "    pid_list = []\n",
    "    sid_list = []\n",
    "    for i in range(len(df_train_series_meta)):\n",
    "        sr = df_train_series_meta.iloc[i]\n",
    "        pid, sid = sr[\"patient_id\"], sr[\"series_id\"]\n",
    "        pid, sid = int(pid), int(sid)\n",
    "        dir_ = f\"data/dataset001/train_images/{pid}/{sid}\"\n",
    "        path_list = os.listdir(dir_)\n",
    "        path_list = [[int(path.replace(\".npy\",\"\")), path] for path in path_list]\n",
    "        path_list.sort()\n",
    "        path_list = [path[1] for path in path_list]\n",
    "        for path in path_list:\n",
    "            image_paths.append(os.path.join(dir_, path))\n",
    "            pid_list.append(pid)\n",
    "            sid_list.append(sid)\n",
    "    # 画像データのDataFrameを作成\n",
    "    df = pd.DataFrame({\n",
    "            'image_path': image_paths,\n",
    "            'patient_id': pid_list,\n",
    "            'series_id': sid_list,\n",
    "            })\n",
    "    return df\n",
    "\n",
    "df = get_dataframe()\n",
    "# 必要\n",
    "df[\"mask_path\"] = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "models = load_models(CFG, mode=\"final\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Code  \n",
    "- シリーズごとの推論の準備\n",
    "- セグメンテーションの前処理及び後処理\n",
    "- 臓器抽出後の分割・保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_series_from_dataset(dir_: str, max_slices: int=200)-> Tuple[np.ndarray, list]:\n",
    "    \"\"\"seriesを読み込む.\n",
    "    Args:\n",
    "        dir_ (str): seriesのディレクトリ.\n",
    "    Returns:\n",
    "        np.ndarray: (Z, H, W)形式の画像の配列.\n",
    "        list: 画像IDのリスト.\n",
    "    \"\"\"\n",
    "    path_list = os.listdir(dir_)\n",
    "    path_list = [[int(path.replace(\".npy\",\"\")), path] for path in path_list]\n",
    "    path_list.sort()\n",
    "    image_id_list = [path[0] for path in path_list]\n",
    "    path_list = [path[1] for path in path_list]\n",
    "\n",
    "\n",
    "    if len(image_id_list) > max_slices:\n",
    "        step = len(image_id_list) // max_slices\n",
    "        image_id_list = image_id_list[::step]\n",
    "        path_list = path_list[::step]\n",
    "\n",
    "    arr = []\n",
    "    for path in path_list:\n",
    "        arr.append(np.load(os.path.join(dir_, path)))\n",
    "    return np.array(arr), image_id_list\n",
    "\n",
    "def morpho_pytorch(masks):\n",
    "    for c in range(masks.shape[-1]):\n",
    "        with torch.no_grad():\n",
    "            arr = torch.tensor(masks[...,c][np.newaxis]).to(CFG.device).to(torch.float32)\n",
    "            #dialation\n",
    "            arr = torch.nn.MaxPool3d(3, stride=1, padding=1, dilation=1, return_indices=False, ceil_mode=False)(arr)\n",
    "            #erosion\n",
    "            arr = -torch.nn.MaxPool3d(3, stride=1, padding=1, dilation=1, return_indices=False, ceil_mode=False)(-arr)\n",
    "        arr = arr.squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "        masks[...,c] = arr\n",
    "    return masks\n",
    "\n",
    "# 各臓器に対して、一定閾値以下のボクセルの集合を切り捨てる\n",
    "area_th = {\n",
    "    \"liver\":50,\n",
    "    \"spleen\":20,\n",
    "    \"kidney\":20,\n",
    "    \"bowel\":30,\n",
    "}\n",
    "\n",
    "def area_0fill(masks):\n",
    "    for idx,mask in enumerate(masks):\n",
    "        for c,th in area_th.items():\n",
    "            c_idx = organ_index_dict[c]\n",
    "            \n",
    "            contours = cv2.findContours(mask[...,c_idx],cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            contours = contours[0] #0番目は元画像,2番目は階層構造。新しいopencvだと1番目のみがコンツーリング情報っぽい\n",
    "            for con in contours:\n",
    "                area = cv2.contourArea(con)\n",
    "                if area <= area_th[c]:\n",
    "                    fill_mask = mask[...,c_idx].copy()\n",
    "                    fill_mask = cv2.drawContours(fill_mask, [con], 0, 0, -1)\n",
    "                    masks[idx,:,:,c_idx] =  fill_mask\n",
    "    return masks\n",
    "\n",
    "def apply_postprocess(mask: np.ndarray)-> np.ndarray:\n",
    "    \"\"\"セグメンテーション後の臓器マスクの後処理.\n",
    "    Args:\n",
    "        mask (numpy.ndarray): (Z, H, W, C)のマスク画像.\n",
    "    \"\"\"\n",
    "    mask = morpho_pytorch(mask)\n",
    "    # mask = area_0fill(mask)\n",
    "    return mask\n",
    "\n",
    "def evaluate_series(CFG: Any, df: pd.DataFrame, models: list, pid: int, sid: int) -> dict:\n",
    "    \"\"\"患者ごと(シリーズごと)の評価を行う.\n",
    "    Args:\n",
    "        CFG (Any): Config\n",
    "        df (pd.DataFrame): get_training_dataframeによって作成したdf\n",
    "        models (list): 学習済みモデルのリスト\n",
    "        pid (int): 患者ID\n",
    "        sid (int): シリーズID\n",
    "    Returns:\n",
    "        dict: 評価結果\n",
    "    \"\"\"\n",
    "    # 評価用データセットの作成\n",
    "    df_res = df[(df[\"patient_id\"] == pid) & (df[\"series_id\"] == sid)].reset_index(drop=True)\n",
    "    if len(df_res) == 0:\n",
    "        raise ValueError(f\"pid:{pid}, sid:{sid} is not found.\")\n",
    "    ds = TestDataset(CFG, df_res, preprocess=apply_preprocess)\n",
    "    eval_iterator = DataLoader(\n",
    "        ds,\n",
    "        shuffle=False,\n",
    "        batch_size=CFG.batch_size,\n",
    "        num_workers=CFG.num_workers\n",
    "    )\n",
    "    # 推論\n",
    "    result = evaluate(CFG, models, eval_iterator)\n",
    "    return result\n",
    "\n",
    "def crop_organ(image: np.ndarray, mask: np.ndarray)-> np.ndarray:\n",
    "    \"\"\"臓器のみを切り抜き、臓器に外接するボリュームを返す.\"\"\"\n",
    "    # 臓器が存在する部分のインデックスを取得\n",
    "    z_indices, h_indices, w_indices = np.where(mask != 0)\n",
    "\n",
    "    \"\"\"# 各軸に沿って最小と最大のインデックスを見つける\n",
    "    z_min, z_max = np.min(z_indices), np.max(z_indices)\n",
    "    h_min, h_max = np.min(h_indices), np.max(h_indices)\n",
    "    w_min, w_max = np.min(w_indices), np.max(w_indices)\"\"\"\n",
    "\n",
    "    # 各軸に沿って、p%のボクセルが含まれる範囲を見つける\n",
    "    p = 98\n",
    "    z_min, z_max = np.percentile(z_indices, 100-p), np.percentile(z_indices, p)\n",
    "    h_min, h_max = np.percentile(h_indices, 100-p), np.percentile(h_indices, p)\n",
    "    w_min, w_max = np.percentile(w_indices, 100-p), np.percentile(w_indices, p)\n",
    "    z_min, z_max = int(z_min), int(z_max)\n",
    "    h_min, h_max = int(h_min), int(h_max)\n",
    "    w_min, w_max = int(w_min), int(w_max)\n",
    "\n",
    "    # この範囲でセグメンテーションデータを切り抜く\n",
    "    margin = 10\n",
    "    z_min, z_max = max(0, z_min - 5), min(image.shape[0], z_max + 5)\n",
    "    h_min, h_max = max(0, h_min - margin), min(image.shape[1], h_max + margin)\n",
    "    w_min, w_max = max(0, w_min - margin), min(image.shape[2], w_max + margin)\n",
    "    cropped_image = image[z_min:z_max+1, h_min:h_max+1, w_min:w_max+1]\n",
    "    cropped_mask = mask[z_min:z_max+1, h_min:h_max+1, w_min:w_max+1]\n",
    "\n",
    "    # crop segmentation\n",
    "    # cropped_image = cropped_image * cropped_mask + (1 - cropped_mask) * -1000\n",
    "\n",
    "    return cropped_image, cropped_mask\n",
    "\n",
    "def kidney_split(image: np.ndarray, mask: np.ndarray)-> np.ndarray:\n",
    "    \"\"\"腎臓について、一度crop_organに入力したものを再度この関数に入力することで左右の腎臓に切り出す.\n",
    "    Note:\n",
    "        本関数中のleft/rightは画像上のleft_rightを表す.\n",
    "    \"\"\"\n",
    "    w_half = image.shape[2] // 2\n",
    "    left_image = image[:, :, :w_half]\n",
    "    left_mask = mask[:, :, :w_half]\n",
    "    right_image = image[:, :, w_half:]\n",
    "    right_mask = mask[:, :, w_half:]\n",
    "    left_image, _ = crop_organ(left_image, left_mask)\n",
    "    right_image, _ = crop_organ(right_image, right_mask)\n",
    "    return left_image, right_image\n",
    "\n",
    "def resize_volume(mask: np.ndarray, hw_shape: tuple)-> np.ndarray:\n",
    "    \"\"\"h, wが512ではない場合にmaskをimageに合うようにリサイズする.\"\"\"\n",
    "    new_arr = []\n",
    "    for i in range(mask.shape[0]):\n",
    "        new_arr.append(cv2.resize(mask[i], hw_shape[::-1]))\n",
    "    return np.stack(new_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    \"\"\"推論パイプライン.\"\"\"\n",
    "    def __init__(self, CFG_SEG: Any):\n",
    "        self.CFG_SEG = CFG_SEG\n",
    "\n",
    "        self.seg_models = seg_load_models(CFG_SEG, mode=\"final\")\n",
    "    \n",
    "    def __call__(self, pid: int, sid: int) -> tuple:\n",
    "        df_study = df_train_series_meta[(df_train_series_meta['patient_id']==pid) & (df_train_series_meta['series_id']==sid)].reset_index(drop=True)\n",
    "        preds = defaultdict(list)\n",
    "        for sid in df_study['series_id'].to_list()[:1]:\n",
    "            image, image_id_list = self.load_data(pid, sid)\n",
    "\n",
    "            masks = self.get_segmentation(image)\n",
    "\n",
    "        return image, image_id_list, masks\n",
    "        \n",
    "\n",
    "\n",
    "    def load_data(self, pid: int, sid: int)-> np.ndarray:\n",
    "        \"\"\"dicomから画像を読み込む.\n",
    "        Args:\n",
    "            pid (int): patient id.\n",
    "            sid (int): series id.\n",
    "        Returns:\n",
    "            np.ndarray: (Z, H, W) normalized CT series.\n",
    "        Note:\n",
    "            - preprocessは全モデル共通なので、ここで行う.\n",
    "            - H, Wはすべてself.CFG_INF.image_sizeにresizeされる.\n",
    "        \"\"\"\n",
    "        image_dir = f\"data/dataset001/train_images/{pid}/{sid}\"\n",
    "        image, image_id_list = load_series_from_dataset(image_dir, max_slices = 200) # ここで最大スライス数も制限\n",
    "        # 現状、モデルごとにwindowing処理が異なるため、ここでのpreprocessはresizeのみ.\n",
    "        image = apply_preprocess(image, resize=self.CFG_SEG.image_size, do_windowing=False)\n",
    "        return image, image_id_list\n",
    "    \n",
    "    def get_segmentation(self, data: np.ndarray)->np.ndarray:\n",
    "        \"\"\"Segmentation modelを使って、各臓器のマスクを作成.\n",
    "        Args:\n",
    "            data: (Z, H, W).\n",
    "        Returns:\n",
    "            mask: (z, h, w, ch) binarized.\"\"\"\n",
    "        seg_iterator = self.pseudo_iterator(self.CFG_SEG, data)\n",
    "        pred = seg_inference(self.CFG_SEG, self.seg_models, seg_iterator)\n",
    "        pred = (pred > 0.5).astype(np.uint8)\n",
    "        return pred\n",
    "        \n",
    "    def pseudo_iterator(self, CFG: Any, images: np.ndarray)-> tuple:\n",
    "        \"\"\"evaluation iterator.\n",
    "        Args:\n",
    "            CFG: config.\n",
    "            images: (batch dim, H, W) or (batch dim, Z, H, W).\n",
    "        \"\"\"\n",
    "        # モデルごとにwindowingが異なるため、ここで行う.\n",
    "        images = apply_preprocess(images, wl=CFG.wl, ww=CFG.ww)\n",
    "        batch = CFG.batch_size\n",
    "        length = len(images)\n",
    "        arr = []\n",
    "        if not CFG.expand_ch_dim:\n",
    "            images = self.add_dummy_array(CFG, images)\n",
    "        for i in range(length):\n",
    "            if CFG.expand_ch_dim:\n",
    "                img = images[i]\n",
    "                img = img[np.newaxis, ...]\n",
    "            else:\n",
    "                img = images[i:i+CFG.n_ch]\n",
    "            arr.append(img)\n",
    "            if i != 0 and (i%batch==0 or i == length-1):\n",
    "                arr = np.stack(arr, axis=0)\n",
    "                arr = torch.from_numpy(arr.astype(arr.dtype, copy=False))\n",
    "                yield arr\n",
    "                arr = []\n",
    "    def add_dummy_array(self, CFG: Any, images: np.ndarray)-> np.ndarray:\n",
    "        \"\"\"chが複数ある場合に、事前に0配列を追加しておく.\"\"\"\n",
    "        add_ch = CFG.n_ch//2\n",
    "        arr = []\n",
    "        img = np.zeros_like(images[0])\n",
    "        for i in range(add_ch):\n",
    "            arr.append(img)\n",
    "        arr.extend(images)\n",
    "        for i in range(add_ch):\n",
    "            arr.append(img)\n",
    "        arr = np.stack(arr, axis=0)\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>aortic_hu</th>\n",
       "      <th>incomplete_organ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004</td>\n",
       "      <td>21057</td>\n",
       "      <td>146.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10004</td>\n",
       "      <td>51033</td>\n",
       "      <td>454.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10005</td>\n",
       "      <td>18667</td>\n",
       "      <td>187.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10007</td>\n",
       "      <td>47578</td>\n",
       "      <td>329.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10026</td>\n",
       "      <td>29700</td>\n",
       "      <td>327.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4706</th>\n",
       "      <td>9961</td>\n",
       "      <td>2003</td>\n",
       "      <td>381.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4707</th>\n",
       "      <td>9961</td>\n",
       "      <td>63032</td>\n",
       "      <td>143.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4708</th>\n",
       "      <td>9980</td>\n",
       "      <td>40214</td>\n",
       "      <td>103.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4709</th>\n",
       "      <td>9980</td>\n",
       "      <td>40466</td>\n",
       "      <td>135.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4710</th>\n",
       "      <td>9983</td>\n",
       "      <td>10806</td>\n",
       "      <td>168.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4711 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  series_id  aortic_hu  incomplete_organ\n",
       "0          10004      21057     146.00                 0\n",
       "1          10004      51033     454.75                 0\n",
       "2          10005      18667     187.00                 0\n",
       "3          10007      47578     329.00                 0\n",
       "4          10026      29700     327.00                 0\n",
       "...          ...        ...        ...               ...\n",
       "4706        9961       2003     381.00                 0\n",
       "4707        9961      63032     143.75                 0\n",
       "4708        9980      40214     103.00                 0\n",
       "4709        9980      40466     135.00                 0\n",
       "4710        9983      10806     168.00                 0\n",
       "\n",
       "[4711 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_series_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liver, spleen, kidneyのいずれかに損傷がある患者のみ抽出\n",
    "injury_pids = df_train[\n",
    "    (df_train[\"liver_low\"] == 1) | \n",
    "    (df_train[\"liver_high\"] == 1) | \n",
    "    (df_train[\"kidney_low\"] == 1) |\n",
    "    (df_train[\"kidney_high\"] == 1) |\n",
    "    (df_train[\"spleen_low\"] == 1) |\n",
    "    (df_train[\"spleen_high\"] == 1)\n",
    "    ][\"patient_id\"].unique()\n",
    "# df_train_series_metaから、該当するpatient_idのみ抽出\n",
    "df_train_series_meta_injury_lsk = df_train_series_meta[df_train_series_meta[\"patient_id\"].isin(injury_pids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference() -> None:\n",
    "    \"\"\"学習用全データに対するセグメンテーション推論を行う.\n",
    "    切り抜いた臓器のCT画像を保存する.\n",
    "    保存は、f'{pid}_{sid}_{organ}.npy'という形式で、スライス位置などの情報を付加せずに外接矩形で保存.\n",
    "    ボリュームサイズは制限せず、元の解像度で保存.\n",
    "    \"\"\"\n",
    "    result_list = []\n",
    "    inference_instance = Inference(CFG)\n",
    "    for i in tqdm(range(len(df_train_series_meta))):# tqdm(range(len(df_train_series_meta_injury_lsk))):\n",
    "        # pid, sid = df_train_series_meta_injury_lsk.iloc[i][[\"patient_id\", \"series_id\"]]\n",
    "        pid, sid = df_train_series_meta.iloc[i][[\"patient_id\", \"series_id\"]]\n",
    "        pid, sid = int(pid), int(sid)\n",
    "        image, image_id_list, masks = inference_instance(pid, sid)\n",
    "        # z軸がinstance_numberとあっていることを確認\n",
    "        assert len(image_id_list) == masks.shape[0]\n",
    "        result = {\n",
    "            \"patient_id\": pid,\n",
    "            \"series_id\": sid,\n",
    "        }\n",
    "        for organ in [\"kidney\", \"liver\", \"spleen\"]:\n",
    "            organ_idx = organ_index_dict[organ]\n",
    "            organ_segment = masks[..., organ_idx]\n",
    "            # z軸のorgan_segmentが少なくとも1以上である最小と最大のインデックスを取得\n",
    "            # 臓器が存在する部分のインデックスを取得\n",
    "            # print(organ_segment.shape)\n",
    "            z_indices, h_indices, w_indices = np.where(organ_segment != 0)\n",
    "            # print(z_indices)\n",
    "            # この部分が適用される例：\n",
    "            # 腎臓が片方しか無く、左右分割したあとに全くボクセルがない方が存在する場合\n",
    "            if z_indices.shape[0] == 0:\n",
    "                result[f\"{organ}_zmin\"] = -1\n",
    "                result[f\"{organ}_zmax\"] = -1\n",
    "\n",
    "            # 各軸に沿って、p%のボクセルが含まれる範囲を見つける\n",
    "            else:\n",
    "                p = 99\n",
    "                z_min, z_max = np.percentile(z_indices, 100 - p), np.percentile(z_indices, p)\n",
    "                z_min, z_max = int(z_min), int(z_max)\n",
    "                result[f\"{organ}_zmin\"] = image_id_list[z_min]\n",
    "                result[f\"{organ}_zmax\"] = image_id_list[z_max]\n",
    "\n",
    "        result_list.append(result)\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4711/4711 [3:26:36<00:00,  2.63s/it]  \n"
     ]
    }
   ],
   "source": [
    "result_list = inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>kidney_zmin</th>\n",
       "      <th>kidney_zmax</th>\n",
       "      <th>liver_zmin</th>\n",
       "      <th>liver_zmax</th>\n",
       "      <th>spleen_zmin</th>\n",
       "      <th>spleen_zmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004</td>\n",
       "      <td>21057</td>\n",
       "      <td>571</td>\n",
       "      <td>756</td>\n",
       "      <td>361</td>\n",
       "      <td>691</td>\n",
       "      <td>396</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10004</td>\n",
       "      <td>51033</td>\n",
       "      <td>572</td>\n",
       "      <td>752</td>\n",
       "      <td>367</td>\n",
       "      <td>692</td>\n",
       "      <td>402</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10005</td>\n",
       "      <td>18667</td>\n",
       "      <td>55</td>\n",
       "      <td>77</td>\n",
       "      <td>37</td>\n",
       "      <td>66</td>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10007</td>\n",
       "      <td>47578</td>\n",
       "      <td>69</td>\n",
       "      <td>84</td>\n",
       "      <td>53</td>\n",
       "      <td>72</td>\n",
       "      <td>56</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10026</td>\n",
       "      <td>29700</td>\n",
       "      <td>109</td>\n",
       "      <td>247</td>\n",
       "      <td>71</td>\n",
       "      <td>239</td>\n",
       "      <td>59</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  series_id  kidney_zmin  kidney_zmax  liver_zmin  liver_zmax  \\\n",
       "0       10004      21057          571          756         361         691   \n",
       "1       10004      51033          572          752         367         692   \n",
       "2       10005      18667           55           77          37          66   \n",
       "3       10007      47578           69           84          53          72   \n",
       "4       10026      29700          109          247          71         239   \n",
       "\n",
       "   spleen_zmin  spleen_zmax  \n",
       "0          396          651  \n",
       "1          402          662  \n",
       "2           43           54  \n",
       "3           56           72  \n",
       "4           59          145  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"outputs/exp065\", exist_ok=True)\n",
    "df.to_csv(\"outputs/exp065/segmentation_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
