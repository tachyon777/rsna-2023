{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp070   \n",
    "[Notion](https://www.notion.so/exp036-6373cb7b504a460dbaf32fc52887e42b?pvs=4)    \n",
    "2.5Dモデルを併せた推論を行うためのパイプライン.  \n",
    "1. exp036 体幹部抽出セグメンテーションモデルを用いたbboxの抽出.  \n",
    "2. exp066 2.5D CNNを用いたモデルの推論実装.  \n",
    "モデルごとのww, wl算出に対応(このnotebookでは高速処理用のため、lsk_prediction内のapply_preprocessのみ変更して対処)  \n",
    "Copy from: exp032.ipynb <- exp028.ipynb <- exp025.ipynb <- exp021.ipynb <- exp018.ipynb <- exp012.ipynb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import defaultdict\n",
    "from typing import Tuple, Any, Dict, Optional\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# リポジトリtopに移動\n",
    "while os.path.basename(os.getcwd()) != 'rsna-2023':\n",
    "    os.chdir('../')\n",
    "    if os.getcwd() == '/':\n",
    "        raise Exception('Could not find project root directory.')\n",
    "    \n",
    "from src.data_io import load_dicom_series\n",
    "from src.segmentation.dataset import TestDataset as SegTestDataset\n",
    "from src.segmentation.model import load_models as seg_load_models\n",
    "from src.segmentation.trainer import inference as seg_inference\n",
    "from src.classification.dataset import TestDatasetBowelExtra, TestDatasetSolidOrgans\n",
    "from src.image_processing import apply_preprocess, crop_organ, kidney_split, resize_volume, \\\n",
    "    apply_postprocess, kidney_specific, resize_3d, resize_1d, create_bbox, crop_image_from_bbox\n",
    "from src.classification.model import load_models as cls_load_models\n",
    "from src.classification.trainer import inference as cls_inference\n",
    "from src.metrics import score, create_training_solution, normalize_probabilities_to_one\n",
    "from src.classification.dataset import load_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG_INF:\n",
    "    exp_name = 'exp_070'\n",
    "    # evaluation時：'train', submission時：'test'\n",
    "    phase = 'train'\n",
    "    base_dir = 'data/rsna-2023-abdominal-trauma-detection'\n",
    "    image_dir = f'data/rsna-2023-abdominal-trauma-detection/{phase}_images'\n",
    "    # dataframeはこのconfigにもたせ、phaseで対応できるようにする.\n",
    "    if phase == 'train':\n",
    "        df = pd.read_csv(os.path.join(base_dir, 'train.csv'))\n",
    "    elif phase == 'test':\n",
    "        df = pd.read_csv(os.path.join(base_dir, 'sample_submission.csv'))\n",
    "    df_series_meta = pd.read_csv(os.path.join(base_dir, f'{phase}_series_meta.csv'))\n",
    "    image_size = (512, 512)\n",
    "    # sample submissionで極端にスライス数が少ない場合があるため対応.\n",
    "    min_slices = 10\n",
    "    # 推論時間制限のため\n",
    "    max_slices = 500\n",
    "    max_series = 2\n",
    "    model_save_dir = \"outputs\"\n",
    "    lsk_model_mode = 'final'\n",
    "    be_model_mode = 'e2'\n",
    "\n",
    "class CFG_LSK:\n",
    "    exp_name = 'exp_056'\n",
    "    # model config\n",
    "    # timm backbone\n",
    "    backbone = 'efficientnet-b4'\n",
    "    n_ch = 1\n",
    "    expand_ch_dim = True\n",
    "    crop_body = False\n",
    "    # n_class: healthy, low, high\n",
    "    n_class = 3\n",
    "    # hyper params\n",
    "    wl = 0\n",
    "    ww = 1000\n",
    "    init_lr = 5e-4\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-4\n",
    "    image_size = (128, 128, 160)\n",
    "    batch_size = 32\n",
    "    amp = False\n",
    "    eps = 1e-8\n",
    "    n_epoch = 24\n",
    "    pretrain = False\n",
    "    freeze_epochs = 0\n",
    "    noaug_epochs = 1\n",
    "    # fold config\n",
    "    n_fold = 6\n",
    "    include_evaluation = False\n",
    "    train_folds = 1\n",
    "    # path\n",
    "    image_dir = \"data/dataset002\"\n",
    "    model_save_dir = \"outputs\"\n",
    "    # other config\n",
    "    seed = 42\n",
    "    num_workers = 4\n",
    "    num_gpus = 2\n",
    "    progress_bar = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    class_weight=torch.tensor([1.0, 1.0, 1.0]).to(device)\n",
    "\n",
    "class CFG_BE:\n",
    "    exp_name = 'exp_068'\n",
    "    # model config\n",
    "    # timm backbone\n",
    "    backbone = 'efficientnet_b4'\n",
    "    # n_ch: z軸方向のスライス数\n",
    "    n_ch = 5\n",
    "    expand_ch_dim = False\n",
    "    # n_class: bowel_injury, extravasation\n",
    "    # sample weighted: 4class\n",
    "    n_class = 1\n",
    "    label_smoothing = None #Optional(float)\n",
    "    crop_body = True\n",
    "    # hyper params\n",
    "    wl = 0\n",
    "    ww = 1000\n",
    "    init_lr = 5e-5\n",
    "    min_lr = 1e-7\n",
    "    weight_decay = 1e-4\n",
    "    image_size = (448, 448)\n",
    "    batch_size = 32\n",
    "    amp = False\n",
    "    eps = 1e-8\n",
    "    n_epoch = 24\n",
    "    iteration_per_epoch = 500\n",
    "    pretrain = True\n",
    "    freeze_epochs = 1\n",
    "    noaug_epochs = 1\n",
    "    # fold config\n",
    "    n_fold = 6\n",
    "    include_evaluation = False\n",
    "    train_folds = 1\n",
    "    # path\n",
    "    image_dir = \"data/dataset001\"\n",
    "    model_save_dir = \"outputs\"\n",
    "    # other config\n",
    "    seed = 42\n",
    "    num_workers = 4\n",
    "    num_gpus = 2\n",
    "    progress_bar = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class CFG_BODY:\n",
    "    exp_name = 'exp_036'\n",
    "    # model config\n",
    "    backbone = 'efficientnet-b3'\n",
    "    n_ch = 1\n",
    "    expand_ch_dim = False\n",
    "    n_class = 1\n",
    "    crop_body = False\n",
    "    # hyper params\n",
    "    wl = 0\n",
    "    ww = 400\n",
    "    init_lr = 1e-3\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-4\n",
    "    image_size = (512, 512)\n",
    "    batch_size = 32\n",
    "    amp = True\n",
    "    n_epoch = 10\n",
    "    # iteration_per_epoch = 200\n",
    "    pretrain = True\n",
    "    freeze_epochs = 0\n",
    "    noaug_epochs = 1\n",
    "    # fold config\n",
    "    n_fold = 6\n",
    "    include_evaluation = False\n",
    "    train_folds = 1\n",
    "    # path\n",
    "    image_dir = \"data/dataset001/train_images\"\n",
    "    mask_dir = \"data/dataset004/segmentations\"\n",
    "    model_save_dir = \"outputs\"\n",
    "    # other config\n",
    "    seed = 42\n",
    "    num_workers = 0\n",
    "    num_gpus = 2\n",
    "    progress_bar = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organs dict (for SEG and LSK models)\n",
    "organ_index_dict_inv = {\n",
    "    0: 'liver',\n",
    "    1: 'spleen',\n",
    "    2: 'kidney',\n",
    "    3: 'bowel'\n",
    "}\n",
    "organ_index_dict = {v: k for k, v in organ_index_dict_inv.items()}\n",
    "\n",
    "# labels dict (for BE models)\n",
    "label_index_dict_inv = {\n",
    "    0: 'bowel',\n",
    "    1: 'extravasation'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_series_from_dataset(dir_: str, max_slices: Optional[int]=None)-> np.ndarray:\n",
    "    \"\"\"seriesを読み込む.\"\"\"\n",
    "    path_list = os.listdir(dir_)\n",
    "    path_list = [[int(path.replace(\".npy\",\"\")), path] for path in path_list]\n",
    "    path_list.sort()\n",
    "    path_list = [path[1] for path in path_list]\n",
    "    if max_slices is not None:\n",
    "        step = (len(path_list) + max_slices - 1) // max_slices\n",
    "        path_list = path_list[::step]\n",
    "    arr = []\n",
    "    for path in path_list:\n",
    "        arr.append(np.load(os.path.join(dir_, path)))\n",
    "    return np.array(arr)\n",
    "\n",
    "def load_image(path: str) -> np.ndarray:\n",
    "    \"\"\"画像の読み込み.\n",
    "    Args:\n",
    "        path (str): 画像のパス.\n",
    "    Returns:\n",
    "        numpy.ndarray: 画像.\n",
    "    Note:\n",
    "        現在読み込む画像の形式は.png, .npy, .npzのみ対応.\n",
    "        cv2.IMREAD_UNCHANGED: 16bit画像やアルファチャンネルを考慮した読み込み.\n",
    "    \"\"\"\n",
    "    if path.endswith(\".png\"):\n",
    "        image = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    elif path.endswith(\".npy\"):\n",
    "        image = np.load(path)\n",
    "    elif path.endswith(\".npz\"):\n",
    "        image = np.load(path)[\"arr_0\"]\n",
    "    else:\n",
    "        raise Exception(f\"unexpected image format: {path}\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    \"\"\"推論パイプライン.\"\"\"\n",
    "    def __init__(self,CFG_INF: Any, CFG_LSK: Any, CFG_BE: Any, CFG_BODY: Any):\n",
    "        self.CFG_INF = CFG_INF\n",
    "        self.CFG_LSK = CFG_LSK\n",
    "        self.CFG_BE = CFG_BE\n",
    "        self.CFG_BODY = CFG_BODY\n",
    "        \n",
    "        self.lsk_models = cls_load_models(CFG_LSK, mode=self.CFG_INF.lsk_model_mode)\n",
    "        self.be_models = cls_load_models(CFG_BE, mode=self.CFG_INF.be_model_mode, framework=\"timm\")\n",
    "\n",
    "        # モデルの読み込み\n",
    "        self.body_models = seg_load_models(self.CFG_BODY, mode=\"final\")\n",
    "    \n",
    "    def __call__(self, pid: int) -> tuple:\n",
    "        \"\"\"inference process.\n",
    "        1. load images from dicom files.\n",
    "        2. create segmentation masks.\n",
    "        3. create liver, spleen, kidney volumes.\n",
    "        4. inference lsk models.\n",
    "        5. inference be models.\n",
    "        Args:\n",
    "            pid (int): patient id.\n",
    "        Return example:\n",
    "            dict: {\n",
    "            'pid': 0,\n",
    "            'bowel_healthy': 0.0,\n",
    "            'bowel_injury': 0.0,\n",
    "            'extravasation_healthy': 0.0,\n",
    "            'extravasation_injury': 0.0,\n",
    "            'kidney_healthy': 0.0,\n",
    "            'kidney_low': 0.0,\n",
    "            'kidney_high': 0.0,\n",
    "            'liver_healthy': 0.0,\n",
    "            'liver_low': 0.0,\n",
    "            'liver_high': 0.0,\n",
    "            'spleen_healthy': 0.0,\n",
    "            'spleen_low': 0.0,\n",
    "            'spleen_high': 0.0\n",
    "            }\n",
    "        Note:\n",
    "            - １症例に複数シリーズ存在する場合、各シリーズに対して推論を行い、全予測結果の最大値を採用する.\n",
    "            - 推論時間的に厳しければ、最初のシリーズのみを採用するなど検討.\n",
    "        \"\"\"\n",
    "        df_study = self.CFG_INF.df_series_meta[self.CFG_INF.df_series_meta['patient_id']==pid].reset_index(drop=True)\n",
    "        # df_study内のそれぞれのシリーズを取得して、画像枚数に対して降順にソート.\n",
    "        df_study = self.get_slices_and_sort(df_study)\n",
    "        preds = defaultdict(list)\n",
    "        for sid in df_study['series_id'].to_list()[:self.CFG_INF.max_series]:\n",
    "            data = self.load_data(pid, sid)\n",
    "            if data is None:\n",
    "                continue\n",
    "            lsk_preds = self.lsk_prediction(pid, sid)\n",
    "            be_preds = self.be_prediction(data)\n",
    "            for idx, organ in organ_index_dict_inv.items():\n",
    "                if idx == 3:\n",
    "                    continue\n",
    "                preds[organ].append(lsk_preds[idx])\n",
    "            for idx, label in label_index_dict_inv.items():\n",
    "                pred = np.array([be_preds[idx]])\n",
    "                preds[label].append(pred)\n",
    "        ret = {'patient_id': pid}\n",
    "        for k,v in preds.items():\n",
    "            v = np.array(v)\n",
    "            ret[k] = np.max(v, axis=0) # seriesごとのmax\n",
    "        ret = self.convert_submission_format(ret)\n",
    "        return ret\n",
    "\n",
    "    def load_data(self, pid: int, sid: int)-> np.ndarray:\n",
    "        \"\"\"dicomから画像を読み込む.\n",
    "        Args:\n",
    "            pid (int): patient id.\n",
    "            sid (int): series id.\n",
    "        Returns:\n",
    "            np.ndarray: (Z, H, W) normalized CT series.\n",
    "        Note:\n",
    "            - preprocessは全モデル共通なので、ここで行う.\n",
    "            - H, Wはすべてself.CFG_INF.image_sizeにresizeされる.\n",
    "        \"\"\"\n",
    "        series_path = os.path.join(self.CFG_BE.image_dir, 'train_images', str(pid), str(sid))\n",
    "        # sample submissionでこういう例が存在する.\n",
    "        if not os.path.exists(series_path):  \n",
    "            return None\n",
    "        image_arr = load_series_from_dataset(series_path, self.CFG_INF.max_slices)\n",
    "        # windowingはしない\n",
    "        image_arr = apply_preprocess(image_arr, resize=self.CFG_INF.image_size, do_windowing=False)\n",
    "        # sample submission対応\n",
    "        if len(image_arr) < self.CFG_INF.min_slices:\n",
    "            image_arr = resize_1d(image_arr, self.CFG_INF.min_slices, axis=0)\n",
    "        return image_arr\n",
    "    \n",
    "    def get_slices_and_sort(self, df_study: pd.DataFrame)-> pd.DataFrame:\n",
    "        \"\"\"シリーズのスライス数を取得して、スライス数に対して降順にソートする.\n",
    "        Args:\n",
    "            df_study (pd.DataFrame): series meta dataframe.\n",
    "        Returns:\n",
    "            pd.DataFrame: sorted series meta dataframe.\n",
    "        \"\"\"\n",
    "        pid = df_study['patient_id'][0]\n",
    "        df_study['n_slices'] = 0\n",
    "        for i in range(len(df_study)):\n",
    "            sid = df_study['series_id'][i]\n",
    "            series_path = os.path.join(self.CFG_INF.image_dir, str(pid), str(sid))\n",
    "            if os.path.exists(series_path):\n",
    "                df_study['n_slices'][i] = len(os.listdir(series_path))\n",
    "        df_study = df_study.sort_values(by='n_slices', ascending=False)\n",
    "        return df_study\n",
    "    \n",
    "    def lsk_prediction(self, pid: int, sid: int)-> np.ndarray:\n",
    "        \"\"\"liver, spleen, kidneyの予測値を返す.\n",
    "        Args:\n",
    "            pid: patient id\n",
    "            sid: series id\n",
    "        Returns:\n",
    "            np.ndarray: (organs, grades).\n",
    "        \"\"\"\n",
    "        volumes = self.get_lsk_volumes(pid, sid) # (organs, z, h, w)\n",
    "        lsk_iterator = self.pseudo_iterator(self.CFG_LSK, volumes)\n",
    "        pred = cls_inference(self.CFG_LSK, self.lsk_models, lsk_iterator)\n",
    "        return pred\n",
    "\n",
    "    def get_lsk_volumes(self, pid: int, sid: int)->Dict[str, np.ndarray]:\n",
    "        \"\"\"Segmentationからliver, spleen, kidneyのvolume dataを作成.\n",
    "        Args:\n",
    "            pid: patient id\n",
    "            sid: series id\n",
    "        Returns:\n",
    "            np.ndarray: (organs, z, h, w).\n",
    "        Note:\n",
    "            - organsはliver, spleen, kidneyの順番.\n",
    "            - この関数内でCFG.LSK.image_sizeのreshapeまで行う.\n",
    "            - 腎臓は左右を分離してからくっつけ直すという特殊な処理が必要.\n",
    "        \"\"\"\n",
    "        arr = []\n",
    "        for idx, organ in organ_index_dict_inv.items():\n",
    "            if idx == 3:\n",
    "                continue\n",
    "            path = os.path.join(self.CFG_LSK.image_dir, str(pid), str(sid), f\"{organ}.npy\")\n",
    "            if organ == \"kidney\":\n",
    "                # 解剖学的な左右を、画像上の左右に置き換えて読み込み\n",
    "                l, r = (\n",
    "                    path.replace(\"kidney.npy\", \"kidney_r.npy\"),\n",
    "                    path.replace(\"kidney.npy\", \"kidney_l.npy\"),\n",
    "                )\n",
    "                if os.path.exists(l):\n",
    "                    l = load_image(l)\n",
    "                else:\n",
    "                    l = np.zeros(self.CFG_LSK.image_size)\n",
    "                if os.path.exists(r):\n",
    "                    r = load_image(r)\n",
    "                else:\n",
    "                    r = np.zeros(self.CFG_LSK.image_size)\n",
    "                img_cropped = kidney_specific(self.CFG_LSK, l, r)\n",
    "            else:\n",
    "                organ_segment = load_image(path)\n",
    "                img_cropped = resize_3d(organ_segment, self.CFG_LSK.image_size)\n",
    "                \n",
    "            arr.append(img_cropped)\n",
    "        arr = np.stack(arr, axis=0)\n",
    "        return arr\n",
    "    \n",
    "    def be_prediction(self, data: np.ndarray)-> np.ndarray:\n",
    "        \"\"\"2.5Dモデルの推論を行う.\n",
    "        Args:\n",
    "            data: (Z, H, W).\n",
    "        Returns:\n",
    "            np.ndarray: [bowel_injury_pred, extravasation_injury_pred].\n",
    "            example: [0.1, 0.9].\n",
    "        \"\"\"\n",
    "        bboxes = self.create_bbox(data) # bounding boxを作成\n",
    "        be_iterator = self.pseudo_iterator(self.CFG_BE, data, bboxes)\n",
    "        pred = cls_inference(self.CFG_BE, self.be_models, be_iterator)\n",
    "        pred = self.be_prediction_postprocess(pred)\n",
    "        return pred\n",
    "    \n",
    "    def get_numerical_prediction(self, pred: np.ndarray)->np.ndarray:\n",
    "        \"\"\"連続する10スライスの予測値が十分に大きい場合、それにふさわしい予測値を返す.\"\"\"\n",
    "        ret = 0\n",
    "        slices = 10\n",
    "        for i in range(0,len(pred)-slices):\n",
    "            ret = max(ret, np.mean(pred[i:i+slices]))\n",
    "        return ret\n",
    "    \n",
    "    def be_prediction_postprocess(self, pred: np.ndarray)-> np.ndarray:\n",
    "        \"\"\"スライスごとの予測をシリーズの予測に変換する.\n",
    "        Args:\n",
    "            pred: (len(data),['bowel_injury', 'extravasation_injury']).\n",
    "        Returns:\n",
    "            np.ndarray: ['bowel_injury', 'extravasation_injury'].\n",
    "        Note:\n",
    "            - 予測値の最大値から外れ値を考慮した2%percentileを採用する.\n",
    "        \"\"\"\n",
    "        assert self.CFG_BE.n_class == 1\n",
    "        extravasation = pred[:, 0]\n",
    "        extravasation = extravasation[2:-2] # dummy両端\n",
    "        extravasation = self.get_numerical_prediction(extravasation)\n",
    "        bowel = 0\n",
    "        return np.array([bowel, extravasation])\n",
    "\n",
    "    def pseudo_iterator(self, CFG: Any, images: np.ndarray, bboxes: Optional[list]=None)-> tuple:\n",
    "        \"\"\"evaluation iterator.\n",
    "        Args:\n",
    "            CFG: config.\n",
    "            images: (batch dim, H, W) or (batch dim, Z, H, W).\n",
    "        \"\"\"\n",
    "        # モデルごとにwindowingが異なるため、ここで行う.\n",
    "        images = apply_preprocess(images, wl=CFG.wl, ww=CFG.ww)\n",
    "        batch = CFG.batch_size\n",
    "        length = len(images)\n",
    "        arr = []\n",
    "        if not CFG.expand_ch_dim:\n",
    "            images = self.add_dummy_array(CFG, images)\n",
    "        for i in range(length):\n",
    "            if CFG.expand_ch_dim:\n",
    "                img = images[i]\n",
    "                img = img[np.newaxis, ...]\n",
    "            else:\n",
    "                img = images[i:i+CFG.n_ch]\n",
    "            if CFG.crop_body:\n",
    "                bbox = bboxes[i]\n",
    "                img = crop_image_from_bbox(img, bbox, ch_first=True)\n",
    "                # ch_last\n",
    "                img = np.transpose(img, (1, 2, 0))\n",
    "                img = cv2.resize(img, CFG.image_size)\n",
    "                # ch_first\n",
    "                img = np.transpose(img, (2, 0, 1))\n",
    "            arr.append(img)\n",
    "            if i != 0 and (i%batch==0 or i == length-1):\n",
    "                arr = np.stack(arr, axis=0)\n",
    "                arr = torch.from_numpy(arr.astype(arr.dtype, copy=False))\n",
    "                yield arr\n",
    "                arr = []\n",
    "\n",
    "    def add_dummy_array(self, CFG: Any, images: np.ndarray)-> np.ndarray:\n",
    "        \"\"\"chが複数ある場合に、事前に0配列を追加しておく.\"\"\"\n",
    "        add_ch = CFG.n_ch//2\n",
    "        arr = []\n",
    "        img = np.zeros_like(images[0])\n",
    "        for i in range(add_ch):\n",
    "            arr.append(img)\n",
    "        arr.extend(images)\n",
    "        for i in range(add_ch):\n",
    "            arr.append(img)\n",
    "        arr = np.stack(arr, axis=0)\n",
    "        return arr\n",
    "    \n",
    "    def convert_submission_format(self, pred: dict)->dict:\n",
    "        \"\"\"提出形式に変換する.\"\"\"\n",
    "        converted = dict()\n",
    "        for idx, organ in organ_index_dict_inv.items():\n",
    "            if idx == 3:\n",
    "                continue\n",
    "            for idx, grade in enumerate(['healthy', 'low', 'high']):\n",
    "                converted[f'{organ}_{grade}'] = pred[organ][idx]\n",
    "        for idx, label in label_index_dict_inv.items():\n",
    "            converted[f'{label}_healthy'] = 1 - pred[label][0]\n",
    "            converted[f'{label}_injury'] = pred[label][0]\n",
    "\n",
    "        converted['patient_id'] = pred['patient_id']\n",
    "        return converted\n",
    "    \n",
    "    def create_bbox(self, data: np.ndarray)-> np.ndarray:\n",
    "        \"\"\"body_crop用セグメンテーションモデルを用いてbboxを抽出、その後画像に適用.\n",
    "        Args:\n",
    "            data: (Z, H, W).\n",
    "        Returns:\n",
    "            list: (Z, 4). zは必ずしもlen(data)と一致しない.\n",
    "        Note:\n",
    "            returnsのshapeはCFG_BE.image_sizeにresize済み.\n",
    "            提出用notebook (apply_preprocessがpseudo_iteratorに組み込まれている場合)はwindowingをこっちに組み込む.  \n",
    "            計算量削減のため、最大32枚しか推論しない.\n",
    "        \"\"\"\n",
    "        step = max(1, (len(data)+32-1) // 32)\n",
    "        data_batch = data[::step]\n",
    "        body_iterator = self.pseudo_iterator(self.CFG_BODY, data_batch)\n",
    "        pred = seg_inference(self.CFG_BODY, self.body_models, body_iterator)\n",
    "        masks = (pred > 0.5).astype(np.uint8)\n",
    "        masks = apply_postprocess(self.CFG_BODY, masks)\n",
    "        bboxes = []\n",
    "        for mask in masks:\n",
    "            bbox = create_bbox(mask)\n",
    "            bboxes.append(bbox)\n",
    "        bboxes_series = []\n",
    "        for i, bbox in enumerate(bboxes):\n",
    "            for j in range(step):\n",
    "                bboxes_series.append(bbox)\n",
    "        return bboxes_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solid_organ = load_df(CFG_LSK)\n",
    "# fold 0のpatient_idを取得\n",
    "pids = df_solid_organ[df_solid_organ[\"fold\"] == 0][\"patient_id\"].unique()\n",
    "df_all = pd.read_csv(os.path.join(CFG_INF.base_dir, 'train.csv'))\n",
    "train_pids = df_solid_organ[df_solid_organ[\"fold\"] != 0][\"patient_id\"].unique()\n",
    "valid_pids = df_solid_organ[df_solid_organ[\"fold\"] == 0][\"patient_id\"].unique()\n",
    "df_train = df_all[df_all[\"patient_id\"].isin(train_pids)].reset_index(drop=True)\n",
    "df_valid = df_all[df_all[\"patient_id\"].isin(valid_pids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_instance = Inference(CFG_INF, CFG_LSK, CFG_BE, CFG_BODY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [27:14<00:00,  3.11s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for pid in tqdm(df_valid['patient_id'].to_list()):\n",
    "    result = inference_instance(pid)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# resultsを保存\n",
    "dir_ = os.path.join(CFG_INF.model_save_dir, CFG_INF.exp_name)\n",
    "os.makedirs(dir_, exist_ok=True)#\n",
    "# path = os.path.join(dir_, \"be_raw_result_e2.pkl\") # \"results_seg004_lsk031_be066.pkl\")\n",
    "path = os.path.join(dir_, \"results_seg004_lsk056_be068.pkl\")\n",
    "# with open(path, 'wb') as f:\n",
    "#    pickle.dump(results, f)\n",
    "\n",
    "# resultsを読み込み\n",
    "with open(path, 'rb') as f:\n",
    "   results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"path = 'outputs/exp_051/spleen_raw_result.pkl'\\nwith open(path, 'rb') as f:\\n    spleen_results = pickle.load(f)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exp032_lsk_result \n",
    "dir = os.path.join(\"/home/medphys3/competition/rsna-2023/outputs/exp_032/results_seg004_lsk031_be026.pkl\")\n",
    "with open(dir, 'rb') as f:\n",
    "    lsk_results = pickle.load(f)\n",
    "\n",
    "# exp051 spleen(weighted) result\n",
    "\"\"\"path = 'outputs/exp_051/spleen_raw_result.pkl'\n",
    "with open(path, 'rb') as f:\n",
    "    spleen_results = pickle.load(f)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_prediction(pred: np.ndarray)->np.ndarray:\n",
    "    \"連続する10スライスの予測値が十分に大きい場合、それにふさわしい予測値を返す.\"\n",
    "    ret = 0\n",
    "    slices = 10\n",
    "    for i in range(0,len(pred)-slices):\n",
    "        ret = max(ret, np.mean(pred[i:i+slices]))\n",
    "            # print(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float32' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/medphys3/competition/rsna-2023/notebooks/exp070.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/medphys3/competition/rsna-2023/notebooks/exp070.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m label, pred \u001b[39min\u001b[39;00m result\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/medphys3/competition/rsna-2023/notebooks/exp070.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     series_max \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/medphys3/competition/rsna-2023/notebooks/exp070.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m pred_series \u001b[39min\u001b[39;00m pred:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/medphys3/competition/rsna-2023/notebooks/exp070.ipynb#X44sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m# (1, slices) -> (slices,)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/medphys3/competition/rsna-2023/notebooks/exp070.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         pred_series \u001b[39m=\u001b[39m pred_series[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/medphys3/competition/rsna-2023/notebooks/exp070.ipynb#X44sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m# p = 90\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/medphys3/competition/rsna-2023/notebooks/exp070.ipynb#X44sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39m# pred_series_to_one = np.percentile(pred_series, p)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float32' object is not iterable"
     ]
    }
   ],
   "source": [
    "result_clean = []\n",
    "for idx, (pid, result) in tqdm(enumerate(zip(df_valid['patient_id'].to_list(), results))):\n",
    "    result_patient = {\n",
    "        \"patient_id\": pid,\n",
    "    }\n",
    "    for label, pred in result.items():\n",
    "        series_max = []\n",
    "        for pred_series in pred:\n",
    "            # (1, slices) -> (slices,)\n",
    "            pred_series = pred_series[0]\n",
    "            # p = 90\n",
    "            # pred_series_to_one = np.percentile(pred_series, p)\n",
    "\n",
    "            pred_series = pred_series[2:-2]\n",
    "            pred_series_to_one = get_numerical_prediction(pred_series)\n",
    "            # pred_seriesをsort\n",
    "            # pred_series = np.sort(pred_series)\n",
    "            # pred_series_to_one = np.mean(pred_series)\n",
    "            series_max.append(pred_series_to_one)\n",
    "        result_patient[label] = np.max(series_max)\n",
    "    result_clean.append(result_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_submission_format(result_clean: list):\n",
    "    \"\"\"提出形式に変換.\"\"\"\n",
    "    result_clean_converted = []\n",
    "    for patient_result in result_clean:\n",
    "        patient_result[\"extravasation_injury\"] = patient_result.pop(\"extravasation\")\n",
    "        patient_result[\"extravasation_healthy\"] = 1 - patient_result[\"extravasation_injury\"]\n",
    "        result_clean_converted.append(patient_result)\n",
    "    return result_clean_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_result = convert_submission_format(result_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(converted_result)):\n",
    "    for key in [\"liver\", \"spleen\", \"kidney\"]:\n",
    "        for key2 in [\"healthy\", \"low\", \"high\"]:\n",
    "            converted_result[i][f\"{key}_{key2}\"] = lsk_results[i][f\"{key}_{key2}\"]\n",
    "    converted_result[i][\"bowel_healthy\"] = 1 - 0.02034\n",
    "    converted_result[i][\"bowel_injury\"] = 0.02034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bowel_healthy</th>\n",
       "      <th>bowel_injury</th>\n",
       "      <th>extravasation_healthy</th>\n",
       "      <th>extravasation_injury</th>\n",
       "      <th>kidney_healthy</th>\n",
       "      <th>kidney_low</th>\n",
       "      <th>kidney_high</th>\n",
       "      <th>liver_healthy</th>\n",
       "      <th>liver_low</th>\n",
       "      <th>liver_high</th>\n",
       "      <th>spleen_healthy</th>\n",
       "      <th>spleen_low</th>\n",
       "      <th>spleen_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727293</td>\n",
       "      <td>0.272707</td>\n",
       "      <td>0.986136</td>\n",
       "      <td>0.013111</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.956367</td>\n",
       "      <td>0.039518</td>\n",
       "      <td>0.007648</td>\n",
       "      <td>0.966071</td>\n",
       "      <td>0.031871</td>\n",
       "      <td>0.005242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911402</td>\n",
       "      <td>0.088598</td>\n",
       "      <td>0.969926</td>\n",
       "      <td>0.027211</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.037186</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.968840</td>\n",
       "      <td>0.029129</td>\n",
       "      <td>0.004682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377910</td>\n",
       "      <td>0.622090</td>\n",
       "      <td>0.986566</td>\n",
       "      <td>0.013668</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>0.986022</td>\n",
       "      <td>0.024402</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.956604</td>\n",
       "      <td>0.102004</td>\n",
       "      <td>0.037002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.567722</td>\n",
       "      <td>0.432278</td>\n",
       "      <td>0.936626</td>\n",
       "      <td>0.055789</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.861548</td>\n",
       "      <td>0.159454</td>\n",
       "      <td>0.095484</td>\n",
       "      <td>0.942492</td>\n",
       "      <td>0.051236</td>\n",
       "      <td>0.012646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.540548</td>\n",
       "      <td>0.459452</td>\n",
       "      <td>0.474337</td>\n",
       "      <td>0.252168</td>\n",
       "      <td>0.273709</td>\n",
       "      <td>0.976180</td>\n",
       "      <td>0.022267</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.949677</td>\n",
       "      <td>0.043361</td>\n",
       "      <td>0.009187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.830580</td>\n",
       "      <td>0.169420</td>\n",
       "      <td>0.982838</td>\n",
       "      <td>0.016038</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.986279</td>\n",
       "      <td>0.012471</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.962978</td>\n",
       "      <td>0.034657</td>\n",
       "      <td>0.005993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614935</td>\n",
       "      <td>0.385065</td>\n",
       "      <td>0.971803</td>\n",
       "      <td>0.026485</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.972280</td>\n",
       "      <td>0.025973</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.947597</td>\n",
       "      <td>0.047442</td>\n",
       "      <td>0.009998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583198</td>\n",
       "      <td>0.416802</td>\n",
       "      <td>0.970040</td>\n",
       "      <td>0.027829</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.735931</td>\n",
       "      <td>0.171892</td>\n",
       "      <td>0.102648</td>\n",
       "      <td>0.660834</td>\n",
       "      <td>0.201816</td>\n",
       "      <td>0.147574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987791</td>\n",
       "      <td>0.012209</td>\n",
       "      <td>0.983758</td>\n",
       "      <td>0.041121</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.985200</td>\n",
       "      <td>0.047233</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.990381</td>\n",
       "      <td>0.016631</td>\n",
       "      <td>0.001992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.903008</td>\n",
       "      <td>0.096992</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.311938</td>\n",
       "      <td>0.487664</td>\n",
       "      <td>0.986423</td>\n",
       "      <td>0.013280</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.982104</td>\n",
       "      <td>0.024652</td>\n",
       "      <td>0.003601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  bowel_healthy  bowel_injury  extravasation_healthy  \\\n",
       "0       10007            1.0           0.0               0.727293   \n",
       "1       10205            1.0           0.0               0.911402   \n",
       "2       10275            1.0           0.0               0.377910   \n",
       "3       10430            1.0           0.0               0.567722   \n",
       "4       10494            1.0           0.0               0.540548   \n",
       "5       10696            1.0           0.0               0.830580   \n",
       "6       10987            1.0           0.0               0.614935   \n",
       "7       11130            1.0           0.0               0.583198   \n",
       "8       11139            1.0           0.0               0.987791   \n",
       "9       11378            1.0           0.0               0.903008   \n",
       "\n",
       "   extravasation_injury  kidney_healthy  kidney_low  kidney_high  \\\n",
       "0              0.272707        0.986136    0.013111     0.001359   \n",
       "1              0.088598        0.969926    0.027211     0.004346   \n",
       "2              0.622090        0.986566    0.013668     0.001456   \n",
       "3              0.432278        0.936626    0.055789     0.014358   \n",
       "4              0.459452        0.474337    0.252168     0.273709   \n",
       "5              0.169420        0.982838    0.016038     0.001869   \n",
       "6              0.385065        0.971803    0.026485     0.003978   \n",
       "7              0.416802        0.970040    0.027829     0.004386   \n",
       "8              0.012209        0.983758    0.041121     0.007898   \n",
       "9              0.096992        0.379310    0.311938     0.487664   \n",
       "\n",
       "   liver_healthy  liver_low  liver_high  spleen_healthy  spleen_low  \\\n",
       "0       0.956367   0.039518    0.007648        0.966071    0.031871   \n",
       "1       0.960000   0.037186    0.006847        0.968840    0.029129   \n",
       "2       0.986022   0.024402    0.003625        0.956604    0.102004   \n",
       "3       0.861548   0.159454    0.095484        0.942492    0.051236   \n",
       "4       0.976180   0.022267    0.003095        0.949677    0.043361   \n",
       "5       0.986279   0.012471    0.001287        0.962978    0.034657   \n",
       "6       0.972280   0.025973    0.003895        0.947597    0.047442   \n",
       "7       0.735931   0.171892    0.102648        0.660834    0.201816   \n",
       "8       0.985200   0.047233    0.009809        0.990381    0.016631   \n",
       "9       0.986423   0.013280    0.001394        0.982104    0.024652   \n",
       "\n",
       "   spleen_high  \n",
       "0     0.005242  \n",
       "1     0.004682  \n",
       "2     0.037002  \n",
       "3     0.012646  \n",
       "4     0.009187  \n",
       "5     0.005993  \n",
       "6     0.009998  \n",
       "7     0.147574  \n",
       "8     0.001992  \n",
       "9     0.003601  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submission = pd.DataFrame(converted_result)\n",
    "submission = pd.DataFrame(results)\n",
    "order = CFG_INF.df.columns.tolist()\n",
    "if \"any_injury\" in order:\n",
    "    order.remove(\"any_injury\")\n",
    "submission = submission[order]\n",
    "submission[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"bowel_healthy\"] = 1 - 0.02034\n",
    "submission[\"bowel_injury\"] = 0.02034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_hack(df:pd.DataFrame)->pd.DataFrame:\n",
    "    \"\"\"bowel, liver, spleen, kidney.いずれかが高い予測値を持つとき、extravasationも合併している確率が高い.\"\"\"\n",
    "    cols = [\"extravasation_injury\", \"liver_low\", \"liver_high\", \"spleen_low\", \"spleen_high\", \"kidney_low\", \"kidney_high\"]\n",
    "    # \"extravasation_injury\", \"bowel_injury\", \n",
    "    df[\"extravasation_injury\"] = df[cols].mean(axis=1)\n",
    "    df[\"extravasation_healthy\"] = 1 - df[\"extravasation_injury\"]\n",
    "    return df\n",
    "submission = metric_hack(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "x = submission[\"extravasation_injury\"]\n",
    "y = df_valid[\"extravasation_injury\"]\n",
    "fpr, tpr, thresholds = roc_curve(y, x)\n",
    "auc = roc_auc_score(y, x)\n",
    "plt.plot(fpr, tpr, marker='o')\n",
    "plt.title(auc)\n",
    "plt.xlabel('FPR: False positive rate')\n",
    "plt.ylabel('TPR: True positive rate')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean: 0.707\n",
    "99%tile: 0.72\n",
    "95%tile:0.69\n",
    "90%tile: 0.68\n",
    "get_numerical_prediction: 0.718"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bowel: 0.1654\n",
      "extravasation: 0.5917\n",
      "kidney: 0.3538\n",
      "liver: 0.5705\n",
      "spleen: 0.5667\n",
      "any_injury: 0.9637\n",
      "mean: 0.5353\n",
      "Training score without scaling: 0.5353\n"
     ]
    }
   ],
   "source": [
    "# add weight\n",
    "solution_train = create_training_solution(df_valid)\n",
    "\n",
    "no_scale_score = score(solution_train.copy(),submission.copy(),'patient_id')\n",
    "print(f'Training score without scaling: {no_scale_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bowel: 0.1596\n",
      "extravasation: 0.4971\n",
      "kidney: 0.3421\n",
      "liver: 0.5652\n",
      "spleen: 0.5550\n",
      "any_injury: 0.5905\n",
      "mean: 0.4516\n",
      "Training score with weight scaling: 0.4516\n"
     ]
    }
   ],
   "source": [
    "# Group by different sample weights\n",
    "scale_by_2 = ['bowel_injury', 'kidney_low','liver_low','spleen_low']\n",
    "scale_by_4 = ['kidney_high','liver_high','spleen_high']\n",
    "scale_by_6 = ['extravasation_injury']\n",
    "\n",
    "# Scale factors based on described metric \n",
    "sf_2 = 2\n",
    "sf_4 = 4\n",
    "sf_6 = 6\n",
    "\n",
    "# Reset the prediction\n",
    "y_pred = submission.copy()\n",
    "\n",
    "# Scale each target \n",
    "y_pred[scale_by_2] *=sf_2\n",
    "y_pred[scale_by_4] *=sf_4\n",
    "y_pred[scale_by_6] *=sf_6\n",
    "\n",
    "weight_scale_score = score(solution_train.copy(),y_pred.copy(),'patient_id')\n",
    "print(f'Training score with weight scaling: {weight_scale_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1466604250.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [83]\u001b[0;36m\u001b[0m\n\u001b[0;31m    Training score with weight scaling: 0.4495\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "bowel: 0.1596\n",
    "extravasation: 0.5070\n",
    "kidney: 0.3229\n",
    "liver: 0.5524\n",
    "spleen: 0.5481\n",
    "any_injury: 0.6071\n",
    "mean: 0.4495\n",
    "Training score with weight scaling: 0.4495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowel: 0.1596\n",
    "extravasation: 0.5237\n",
    "kidney: 0.3229\n",
    "liver: 0.5524\n",
    "spleen: 0.5928\n",
    "any_injury: 0.6061\n",
    "mean: 0.4596\n",
    "Training score with weight scaling: 0.4596"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bowel: 0.1508\n",
    "extravasation: 0.5704\n",
    "kidney: 0.3229\n",
    "liver: 0.5524\n",
    "spleen: 0.5928\n",
    "any_injury: 0.6130\n",
    "mean: 0.4671\n",
    "Training score with weight scaling: 0.4671"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean, sf30\n",
    "bowel: 0.1508\n",
    "extravasation: 0.5519\n",
    "kidney: 0.3229\n",
    "liver: 0.5524\n",
    "spleen: 0.5928\n",
    "any_injury: 0.6203\n",
    "mean: 0.4652\n",
    "Training score with weight scaling: 0.4652"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
