{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp077   \n",
    "[Notion](https://www.notion.so/exp077-710ca4e3dddd4b498371fa49f35f9065?pvs=4)    \n",
    "2.5Dモデル(lsk, low, high)(exp075)の推論及び評価を行う.  \n",
    "beモデルは最も精度の高いexp068のe2の予測結果を用いる.  \n",
    "結果が良ければ、3d lskモデルとの平均も試す.  \n",
    "Copy from: exp077 <- exp032.ipynb <- exp028.ipynb <- exp025.ipynb <- exp021.ipynb <- exp018.ipynb <- exp012.ipynb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import defaultdict\n",
    "from typing import Tuple, Any, Dict, Optional\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# リポジトリtopに移動\n",
    "while os.path.basename(os.getcwd()) != 'rsna-2023':\n",
    "    os.chdir('../')\n",
    "    if os.getcwd() == '/':\n",
    "        raise Exception('Could not find project root directory.')\n",
    "    \n",
    "from src.data_io import load_dicom_series\n",
    "from src.segmentation.dataset import TestDataset as SegTestDataset\n",
    "from src.segmentation.model import load_models as seg_load_models\n",
    "from src.segmentation.trainer import inference as seg_inference\n",
    "from src.classification.dataset import TestDatasetBowelExtra, TestDatasetSolidOrgans\n",
    "from src.image_processing import apply_preprocess, crop_organ, kidney_split, resize_volume, \\\n",
    "    apply_postprocess, kidney_specific, resize_3d, resize_1d, create_bbox, crop_image_from_bbox\n",
    "from src.classification.model import load_models as cls_load_models\n",
    "from src.classification.trainer import inference as cls_inference\n",
    "from src.metrics import score, create_training_solution, normalize_probabilities_to_one\n",
    "from src.classification.dataset import load_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG_INF:\n",
    "    exp_name = 'exp_077'\n",
    "    # evaluation時：'train', submission時：'test'\n",
    "    phase = 'train'\n",
    "    base_dir = 'data/rsna-2023-abdominal-trauma-detection'\n",
    "    image_dir = f'data/rsna-2023-abdominal-trauma-detection/{phase}_images'\n",
    "    # dataframeはこのconfigにもたせ、phaseで対応できるようにする.\n",
    "    if phase == 'train':\n",
    "        df = pd.read_csv(os.path.join(base_dir, 'train.csv'))\n",
    "    elif phase == 'test':\n",
    "        df = pd.read_csv(os.path.join(base_dir, 'sample_submission.csv'))\n",
    "    df_series_meta = pd.read_csv(os.path.join(base_dir, f'{phase}_series_meta.csv'))\n",
    "    image_size = (512, 512)\n",
    "    # sample submissionで極端にスライス数が少ない場合があるため対応.\n",
    "    min_slices = 10\n",
    "    # 推論時間制限のため\n",
    "    max_slices = 500\n",
    "    max_series = 2\n",
    "    model_save_dir = \"outputs\"\n",
    "    lsk_model_mode = 'final'\n",
    "    be_model_mode = 'e2'\n",
    "    lsk_2d_model_mode = 'e10'\n",
    "\n",
    "class CFG_LSK:\n",
    "    exp_name = 'exp_056'\n",
    "    # model config\n",
    "    # timm backbone\n",
    "    backbone = 'efficientnet-b4'\n",
    "    n_ch = 1\n",
    "    expand_ch_dim = True\n",
    "    crop_body = False\n",
    "    # n_class: healthy, low, high\n",
    "    n_class = 3\n",
    "    # hyper params\n",
    "    wl = 0\n",
    "    ww = 1000\n",
    "    init_lr = 5e-4\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-4\n",
    "    image_size = (128, 128, 160)\n",
    "    batch_size = 32\n",
    "    amp = False\n",
    "    eps = 1e-8\n",
    "    n_epoch = 24\n",
    "    pretrain = False\n",
    "    freeze_epochs = 0\n",
    "    noaug_epochs = 1\n",
    "    # fold config\n",
    "    n_fold = 6\n",
    "    include_evaluation = False\n",
    "    train_folds = 1\n",
    "    # path\n",
    "    image_dir = \"data/dataset002\"\n",
    "    model_save_dir = \"outputs\"\n",
    "    # other config\n",
    "    seed = 42\n",
    "    num_workers = 4\n",
    "    num_gpus = 2\n",
    "    progress_bar = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    class_weight=torch.tensor([1.0, 1.0, 1.0]).to(device)\n",
    "\n",
    "class CFG_BE:\n",
    "    exp_name = 'exp_068'\n",
    "    # model config\n",
    "    # timm backbone\n",
    "    backbone = 'efficientnet_b4'\n",
    "    # n_ch: z軸方向のスライス数\n",
    "    n_ch = 5\n",
    "    expand_ch_dim = False\n",
    "    # n_class: bowel_injury, extravasation\n",
    "    # sample weighted: 4class\n",
    "    n_class = 1\n",
    "    label_smoothing = None #Optional(float)\n",
    "    crop_body = True\n",
    "    # hyper params\n",
    "    wl = 0\n",
    "    ww = 1000\n",
    "    init_lr = 5e-5\n",
    "    min_lr = 1e-7\n",
    "    weight_decay = 1e-4\n",
    "    image_size = (448, 448)\n",
    "    batch_size = 32\n",
    "    amp = False\n",
    "    eps = 1e-8\n",
    "    n_epoch = 24\n",
    "    iteration_per_epoch = 500\n",
    "    pretrain = True\n",
    "    freeze_epochs = 1\n",
    "    noaug_epochs = 1\n",
    "    # fold config\n",
    "    n_fold = 6\n",
    "    include_evaluation = False\n",
    "    train_folds = 1\n",
    "    # path\n",
    "    image_dir = \"data/dataset001\"\n",
    "    model_save_dir = \"outputs\"\n",
    "    # other config\n",
    "    seed = 42\n",
    "    num_workers = 4\n",
    "    num_gpus = 2\n",
    "    progress_bar = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class CFG_BODY:\n",
    "    exp_name = 'exp_036'\n",
    "    # model config\n",
    "    backbone = 'efficientnet-b3'\n",
    "    n_ch = 1\n",
    "    expand_ch_dim = False\n",
    "    n_class = 1\n",
    "    crop_body = False\n",
    "    # hyper params\n",
    "    wl = 0\n",
    "    ww = 400\n",
    "    init_lr = 1e-3\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-4\n",
    "    image_size = (512, 512)\n",
    "    batch_size = 32\n",
    "    amp = True\n",
    "    n_epoch = 10\n",
    "    # iteration_per_epoch = 200\n",
    "    pretrain = True\n",
    "    freeze_epochs = 0\n",
    "    noaug_epochs = 1\n",
    "    # fold config\n",
    "    n_fold = 6\n",
    "    include_evaluation = False\n",
    "    train_folds = 1\n",
    "    # path\n",
    "    image_dir = \"data/dataset001/train_images\"\n",
    "    mask_dir = \"data/dataset004/segmentations\"\n",
    "    model_save_dir = \"outputs\"\n",
    "    # other config\n",
    "    seed = 42\n",
    "    num_workers = 0\n",
    "    num_gpus = 2\n",
    "    progress_bar = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class CFG_LSK_2D:\n",
    "    exp_name = 'exp_075'\n",
    "    # model config\n",
    "    # timm backbone\n",
    "    backbone = 'efficientnet_b4'\n",
    "    # n_ch: z軸方向のスライス数\n",
    "    n_ch = 5\n",
    "    expand_ch_dim = False\n",
    "    # n_class: lsk*(low+high)\n",
    "    n_class = 6\n",
    "    label_smoothing = None #Optional(float)\n",
    "    crop_body = True\n",
    "    # hyper params\n",
    "    wl = 0\n",
    "    ww = 1000\n",
    "    init_lr = 5e-5\n",
    "    min_lr = 1e-7\n",
    "    weight_decay = 1e-4\n",
    "    image_size = (448, 448)\n",
    "    batch_size = 32\n",
    "    amp = False\n",
    "    eps = 1e-8\n",
    "    n_epoch = 14\n",
    "    iteration_per_epoch = 500\n",
    "    pretrain = True\n",
    "    freeze_epochs = 1\n",
    "    noaug_epochs = 1\n",
    "    # fold config\n",
    "    n_fold = 6\n",
    "    include_evaluation = False\n",
    "    train_folds = 1\n",
    "    # path\n",
    "    image_dir = \"data/dataset001\"\n",
    "    model_save_dir = \"outputs\"\n",
    "    # other config\n",
    "    seed = 42\n",
    "    num_workers = 4\n",
    "    num_gpus = 2\n",
    "    progress_bar = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # b_healty, b_injury, e_healty, e_injury\n",
    "    class_weight=torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organs dict (for SEG and LSK models)\n",
    "organ_index_dict_inv = {\n",
    "    0: 'liver',\n",
    "    1: 'spleen',\n",
    "    2: 'kidney',\n",
    "    3: 'bowel'\n",
    "}\n",
    "organ_index_dict = {v: k for k, v in organ_index_dict_inv.items()}\n",
    "\n",
    "# labels dict (for BE models)\n",
    "label_index_dict_inv = {\n",
    "    0: 'bowel',\n",
    "    1: 'extravasation'\n",
    "}\n",
    "\n",
    "lsk_2d_model_label_info = {\n",
    "    0: \"liver_low\",\n",
    "    1: \"liver_high\",\n",
    "    2: \"spleen_low\",\n",
    "    3: \"spleen_high\",\n",
    "    4: \"kidney_low\",\n",
    "    5: \"kidney_high\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_series_from_dataset(dir_: str, max_slices: Optional[int]=None)-> np.ndarray:\n",
    "    \"\"\"seriesを読み込む.\"\"\"\n",
    "    path_list = os.listdir(dir_)\n",
    "    path_list = [[int(path.replace(\".npy\",\"\")), path] for path in path_list]\n",
    "    path_list.sort()\n",
    "    path_list = [path[1] for path in path_list]\n",
    "    if max_slices is not None:\n",
    "        step = (len(path_list) + max_slices - 1) // max_slices\n",
    "        path_list = path_list[::step]\n",
    "    arr = []\n",
    "    for path in path_list:\n",
    "        arr.append(np.load(os.path.join(dir_, path)))\n",
    "    return np.array(arr)\n",
    "\n",
    "def load_image(path: str) -> np.ndarray:\n",
    "    \"\"\"画像の読み込み.\n",
    "    Args:\n",
    "        path (str): 画像のパス.\n",
    "    Returns:\n",
    "        numpy.ndarray: 画像.\n",
    "    Note:\n",
    "        現在読み込む画像の形式は.png, .npy, .npzのみ対応.\n",
    "        cv2.IMREAD_UNCHANGED: 16bit画像やアルファチャンネルを考慮した読み込み.\n",
    "    \"\"\"\n",
    "    if path.endswith(\".png\"):\n",
    "        image = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    elif path.endswith(\".npy\"):\n",
    "        image = np.load(path)\n",
    "    elif path.endswith(\".npz\"):\n",
    "        image = np.load(path)[\"arr_0\"]\n",
    "    else:\n",
    "        raise Exception(f\"unexpected image format: {path}\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    \"\"\"推論パイプライン.\"\"\"\n",
    "    def __init__(self,CFG_INF: Any, CFG_LSK: Any, CFG_BE: Any, CFG_BODY: Any, CFG_LSK_2D: Any):\n",
    "        self.CFG_INF = CFG_INF\n",
    "        self.CFG_LSK = CFG_LSK\n",
    "        self.CFG_BE = CFG_BE\n",
    "        self.CFG_BODY = CFG_BODY\n",
    "        self.CFG_LSK_2D = CFG_LSK_2D\n",
    "\n",
    "        self.lsk_models = cls_load_models(CFG_LSK, mode=self.CFG_INF.lsk_model_mode)\n",
    "        self.be_models = cls_load_models(CFG_BE, mode=self.CFG_INF.be_model_mode, framework=\"timm\")\n",
    "        self.lsk_2d_models = cls_load_models(CFG_LSK_2D, mode=self.CFG_INF.lsk_2d_model_mode, framework=\"timm\")\n",
    "\n",
    "        # z軸を求めるためのorgan label\n",
    "        self.organ_label = pd.read_csv(\"outputs/exp065/segmentation_result.csv\")\n",
    "\n",
    "        # モデルの読み込み\n",
    "        self.body_models = seg_load_models(self.CFG_BODY, mode=\"final\")\n",
    "    \n",
    "    def __call__(self, pid: int) -> tuple:\n",
    "        \"\"\"inference process.\n",
    "        1. load images from dicom files.\n",
    "        2. create segmentation masks.\n",
    "        3. create liver, spleen, kidney volumes.\n",
    "        4. inference lsk models.\n",
    "        5. inference be models.\n",
    "        Args:\n",
    "            pid (int): patient id.\n",
    "        Return example:\n",
    "            dict: {\n",
    "            'pid': 0,\n",
    "            'bowel_healthy': 0.0,\n",
    "            'bowel_injury': 0.0,\n",
    "            'extravasation_healthy': 0.0,\n",
    "            'extravasation_injury': 0.0,\n",
    "            'kidney_healthy': 0.0,\n",
    "            'kidney_low': 0.0,\n",
    "            'kidney_high': 0.0,\n",
    "            'liver_healthy': 0.0,\n",
    "            'liver_low': 0.0,\n",
    "            'liver_high': 0.0,\n",
    "            'spleen_healthy': 0.0,\n",
    "            'spleen_low': 0.0,\n",
    "            'spleen_high': 0.0\n",
    "            }\n",
    "        Note:\n",
    "            - １症例に複数シリーズ存在する場合、各シリーズに対して推論を行い、全予測結果の最大値を採用する.\n",
    "            - 推論時間的に厳しければ、最初のシリーズのみを採用するなど検討.\n",
    "        \"\"\"\n",
    "        df_study = self.CFG_INF.df_series_meta[self.CFG_INF.df_series_meta['patient_id']==pid].reset_index(drop=True)\n",
    "        # df_study内のそれぞれのシリーズを取得して、画像枚数に対して降順にソート.\n",
    "        df_study = self.get_slices_and_sort(df_study)\n",
    "        preds = defaultdict(list)\n",
    "        for sid in df_study['series_id'].to_list()[:self.CFG_INF.max_series]:\n",
    "            data = self.load_data(pid, sid)\n",
    "            if data is None:\n",
    "                continue\n",
    "            # lsk_preds = self.lsk_prediction(pid, sid)\n",
    "            # be_preds = self.be_prediction(data)\n",
    "            lsk_2d_preds = self.lsk_2d_prediction(pid, sid, data)\n",
    "            for idx, label in lsk_2d_model_label_info.items():\n",
    "                pred = np.array([lsk_2d_preds[:,idx]]) # [:,idx] when postprocess is not applied\n",
    "                preds[label].append(pred)\n",
    "            return preds\n",
    "            for idx, organ in organ_index_dict_inv.items():\n",
    "                if idx == 3:\n",
    "                    continue\n",
    "                preds[organ].append(lsk_preds[idx])\n",
    "            for idx, label in label_index_dict_inv.items():\n",
    "                pred = np.array([be_preds[idx]])\n",
    "                preds[label].append(pred)\n",
    "        ret = {'patient_id': pid}\n",
    "        for k,v in preds.items():\n",
    "            v = np.array(v)\n",
    "            ret[k] = np.max(v, axis=0) # seriesごとのmax\n",
    "        ret = self.convert_submission_format(ret)\n",
    "        return ret\n",
    "\n",
    "    def load_data(self, pid: int, sid: int)-> np.ndarray:\n",
    "        \"\"\"dicomから画像を読み込む.\n",
    "        Args:\n",
    "            pid (int): patient id.\n",
    "            sid (int): series id.\n",
    "        Returns:\n",
    "            np.ndarray: (Z, H, W) normalized CT series.\n",
    "        Note:\n",
    "            - preprocessは全モデル共通なので、ここで行う.\n",
    "            - H, Wはすべてself.CFG_INF.image_sizeにresizeされる.\n",
    "        \"\"\"\n",
    "        series_path = os.path.join(self.CFG_BE.image_dir, 'train_images', str(pid), str(sid))\n",
    "        # sample submissionでこういう例が存在する.\n",
    "        if not os.path.exists(series_path):  \n",
    "            return None\n",
    "        image_arr = load_series_from_dataset(series_path, self.CFG_INF.max_slices)\n",
    "        # windowingはしない\n",
    "        image_arr = apply_preprocess(image_arr, resize=self.CFG_INF.image_size, do_windowing=False)\n",
    "        # sample submission対応\n",
    "        if len(image_arr) < self.CFG_INF.min_slices:\n",
    "            image_arr = resize_1d(image_arr, self.CFG_INF.min_slices, axis=0)\n",
    "        return image_arr\n",
    "    \n",
    "    def get_slices_and_sort(self, df_study: pd.DataFrame)-> pd.DataFrame:\n",
    "        \"\"\"シリーズのスライス数を取得して、スライス数に対して降順にソートする.\n",
    "        Args:\n",
    "            df_study (pd.DataFrame): series meta dataframe.\n",
    "        Returns:\n",
    "            pd.DataFrame: sorted series meta dataframe.\n",
    "        \"\"\"\n",
    "        pid = df_study['patient_id'][0]\n",
    "        df_study['n_slices'] = 0\n",
    "        for i in range(len(df_study)):\n",
    "            sid = df_study['series_id'][i]\n",
    "            series_path = os.path.join(self.CFG_INF.image_dir, str(pid), str(sid))\n",
    "            if os.path.exists(series_path):\n",
    "                df_study['n_slices'][i] = len(os.listdir(series_path))\n",
    "        df_study = df_study.sort_values(by='n_slices', ascending=False)\n",
    "        return df_study\n",
    "    \n",
    "    def lsk_prediction(self, pid: int, sid: int)-> np.ndarray:\n",
    "        \"\"\"liver, spleen, kidneyの予測値を返す.\n",
    "        Args:\n",
    "            pid: patient id\n",
    "            sid: series id\n",
    "        Returns:\n",
    "            np.ndarray: (organs, grades).\n",
    "        \"\"\"\n",
    "        volumes = self.get_lsk_volumes(pid, sid) # (organs, z, h, w)\n",
    "        lsk_iterator = self.pseudo_iterator(self.CFG_LSK, volumes)\n",
    "        pred = cls_inference(self.CFG_LSK, self.lsk_models, lsk_iterator)\n",
    "        return pred\n",
    "    \n",
    "    def get_z_indices(self, pid: int, sid: int)-> Tuple[int, int]:\n",
    "        \"\"\"提出用コードでは処理異なるので注意.\"\"\"\n",
    "        df = self.organ_label\n",
    "        df = df[(df['patient_id']==pid) & (df['series_id']==sid)]\n",
    "        z_min = 10**5\n",
    "        z_max = 0\n",
    "        for organ in [\"liver\", \"spleen\", \"kidney\"]:\n",
    "            z_min = min(z_min, df[f'{organ}_zmin'].values[0])\n",
    "            z_max = max(z_max, df[f'{organ}_zmax'].values[0])\n",
    "        return z_min, z_max\n",
    "    \n",
    "    def z_indices_cut(self, pid: int, sid: int, data: np.ndarray, bboxes: list):\n",
    "        \"\"\"z軸方向に対して、必要なスライスのみを抽出する.\n",
    "        Args:\n",
    "            pid: patient id\n",
    "            sid: series id\n",
    "            data: (Z, H, W)\n",
    "            bboxes: (Z, 4)\n",
    "        Returns:\n",
    "            np.ndarray: (Z, H, W)\n",
    "        \"\"\"\n",
    "        z_min, z_max = self.get_z_indices(pid, sid)\n",
    "        z_min = max(0, z_min)\n",
    "        z_max = min(len(data), z_max)\n",
    "        data = data[z_min:z_max]\n",
    "        bboxes = bboxes[z_min:z_max]\n",
    "        return data, bboxes\n",
    "\n",
    "\n",
    "\n",
    "    def get_lsk_volumes(self, pid: int, sid: int)->Dict[str, np.ndarray]:\n",
    "        \"\"\"Segmentationからliver, spleen, kidneyのvolume dataを作成.\n",
    "        Args:\n",
    "            pid: patient id\n",
    "            sid: series id\n",
    "        Returns:\n",
    "            np.ndarray: (organs, z, h, w).\n",
    "        Note:\n",
    "            - organsはliver, spleen, kidneyの順番.\n",
    "            - この関数内でCFG.LSK.image_sizeのreshapeまで行う.\n",
    "            - 腎臓は左右を分離してからくっつけ直すという特殊な処理が必要.\n",
    "        \"\"\"\n",
    "        arr = []\n",
    "        for idx, organ in organ_index_dict_inv.items():\n",
    "            if idx == 3:\n",
    "                continue\n",
    "            path = os.path.join(self.CFG_LSK.image_dir, str(pid), str(sid), f\"{organ}.npy\")\n",
    "            if organ == \"kidney\":\n",
    "                # 解剖学的な左右を、画像上の左右に置き換えて読み込み\n",
    "                l, r = (\n",
    "                    path.replace(\"kidney.npy\", \"kidney_r.npy\"),\n",
    "                    path.replace(\"kidney.npy\", \"kidney_l.npy\"),\n",
    "                )\n",
    "                if os.path.exists(l):\n",
    "                    l = load_image(l)\n",
    "                else:\n",
    "                    l = np.zeros(self.CFG_LSK.image_size)\n",
    "                if os.path.exists(r):\n",
    "                    r = load_image(r)\n",
    "                else:\n",
    "                    r = np.zeros(self.CFG_LSK.image_size)\n",
    "                img_cropped = kidney_specific(self.CFG_LSK, l, r)\n",
    "            else:\n",
    "                organ_segment = load_image(path)\n",
    "                img_cropped = resize_3d(organ_segment, self.CFG_LSK.image_size)\n",
    "                \n",
    "            arr.append(img_cropped)\n",
    "        arr = np.stack(arr, axis=0)\n",
    "        return arr\n",
    "    \n",
    "    def be_prediction(self, data: np.ndarray)-> np.ndarray:\n",
    "        \"\"\"2.5Dモデルの推論を行う.\n",
    "        Args:\n",
    "            data: (Z, H, W).\n",
    "        Returns:\n",
    "            np.ndarray: [bowel_injury_pred, extravasation_injury_pred].\n",
    "            example: [0.1, 0.9].\n",
    "        \"\"\"\n",
    "        bboxes = self.create_bbox(data) # bounding boxを作成\n",
    "        self.bboxes = bboxes\n",
    "        be_iterator = self.pseudo_iterator(self.CFG_BE, data, bboxes)\n",
    "        pred = cls_inference(self.CFG_BE, self.be_models, be_iterator)\n",
    "        pred = self.be_prediction_postprocess(pred)\n",
    "        return pred\n",
    "    \n",
    "    def get_numerical_prediction(self, pred: np.ndarray)->np.ndarray:\n",
    "        \"\"\"連続する10スライスの予測値が十分に大きい場合、それにふさわしい予測値を返す.\"\"\"\n",
    "        ret = 0\n",
    "        slices = 10\n",
    "        for i in range(0,len(pred)-slices):\n",
    "            ret = max(ret, np.mean(pred[i:i+slices]))\n",
    "        return ret\n",
    "    \n",
    "    def be_prediction_postprocess(self, pred: np.ndarray)-> np.ndarray:\n",
    "        \"\"\"スライスごとの予測をシリーズの予測に変換する.\n",
    "        Args:\n",
    "            pred: (len(data),['bowel_injury', 'extravasation_injury']).\n",
    "        Returns:\n",
    "            np.ndarray: ['bowel_injury', 'extravasation_injury'].\n",
    "        Note:\n",
    "            - 予測値の最大値から外れ値を考慮した2%percentileを採用する.\n",
    "        \"\"\"\n",
    "        assert self.CFG_BE.n_class == 1\n",
    "        extravasation = pred[:, 0]\n",
    "        extravasation = extravasation[2:-2] # dummy両端\n",
    "        extravasation = self.get_numerical_prediction(extravasation)\n",
    "        bowel = 0\n",
    "        return np.array([bowel, extravasation])\n",
    "\n",
    "    def pseudo_iterator(self, CFG: Any, images: np.ndarray, bboxes: Optional[list]=None)-> tuple:\n",
    "        \"\"\"evaluation iterator.\n",
    "        Args:\n",
    "            CFG: config.\n",
    "            images: (batch dim, H, W) or (batch dim, Z, H, W).\n",
    "        \"\"\"\n",
    "        # モデルごとにwindowingが異なるため、ここで行う.\n",
    "        images = apply_preprocess(images, wl=CFG.wl, ww=CFG.ww)\n",
    "        batch = CFG.batch_size\n",
    "        length = len(images)\n",
    "        arr = []\n",
    "        if not CFG.expand_ch_dim:\n",
    "            images = self.add_dummy_array(CFG, images)\n",
    "        for i in range(length):\n",
    "            if CFG.expand_ch_dim:\n",
    "                img = images[i]\n",
    "                img = img[np.newaxis, ...]\n",
    "            else:\n",
    "                img = images[i:i+CFG.n_ch]\n",
    "            if CFG.crop_body:\n",
    "                bbox = bboxes[i]\n",
    "                img = crop_image_from_bbox(img, bbox, ch_first=True)\n",
    "                # ch_last\n",
    "                img = np.transpose(img, (1, 2, 0))\n",
    "                img = cv2.resize(img, CFG.image_size)\n",
    "                # ch_first\n",
    "                img = np.transpose(img, (2, 0, 1))\n",
    "            arr.append(img)\n",
    "            if i != 0 and (i%batch==0 or i == length-1):\n",
    "                arr = np.stack(arr, axis=0)\n",
    "                arr = torch.from_numpy(arr.astype(arr.dtype, copy=False))\n",
    "                yield arr\n",
    "                arr = []\n",
    "\n",
    "    def add_dummy_array(self, CFG: Any, images: np.ndarray)-> np.ndarray:\n",
    "        \"\"\"chが複数ある場合に、事前に0配列を追加しておく.\"\"\"\n",
    "        add_ch = CFG.n_ch//2\n",
    "        arr = []\n",
    "        img = np.zeros_like(images[0])\n",
    "        for i in range(add_ch):\n",
    "            arr.append(img)\n",
    "        arr.extend(images)\n",
    "        for i in range(add_ch):\n",
    "            arr.append(img)\n",
    "        arr = np.stack(arr, axis=0)\n",
    "        return arr\n",
    "    \n",
    "    def convert_submission_format(self, pred: dict)->dict:\n",
    "        \"\"\"提出形式に変換する.\"\"\"\n",
    "        converted = dict()\n",
    "        for idx, organ in organ_index_dict_inv.items():\n",
    "            if idx == 3:\n",
    "                continue\n",
    "            for idx, grade in enumerate(['healthy', 'low', 'high']):\n",
    "                converted[f'{organ}_{grade}'] = pred[organ][idx]\n",
    "        for idx, label in label_index_dict_inv.items():\n",
    "            converted[f'{label}_healthy'] = 1 - pred[label][0]\n",
    "            converted[f'{label}_injury'] = pred[label][0]\n",
    "\n",
    "        converted['patient_id'] = pred['patient_id']\n",
    "        return converted\n",
    "    \n",
    "    def create_bbox(self, data: np.ndarray)-> np.ndarray:\n",
    "        \"\"\"body_crop用セグメンテーションモデルを用いてbboxを抽出、その後画像に適用.\n",
    "        Args:\n",
    "            data: (Z, H, W).\n",
    "        Returns:\n",
    "            list: (Z, 4). zは必ずしもlen(data)と一致しない.\n",
    "        Note:\n",
    "            returnsのshapeはCFG_BE.image_sizeにresize済み.\n",
    "            提出用notebook (apply_preprocessがpseudo_iteratorに組み込まれている場合)はwindowingをこっちに組み込む.  \n",
    "            計算量削減のため、最大32枚しか推論しない.\n",
    "        \"\"\"\n",
    "        step = max(1, (len(data)+32-1) // 32)\n",
    "        data_batch = data[::step]\n",
    "        body_iterator = self.pseudo_iterator(self.CFG_BODY, data_batch)\n",
    "        pred = seg_inference(self.CFG_BODY, self.body_models, body_iterator)\n",
    "        masks = (pred > 0.5).astype(np.uint8)\n",
    "        masks = apply_postprocess(self.CFG_BODY, masks)\n",
    "        bboxes = []\n",
    "        for mask in masks:\n",
    "            bbox = create_bbox(mask)\n",
    "            bboxes.append(bbox)\n",
    "        bboxes_series = []\n",
    "        for i, bbox in enumerate(bboxes):\n",
    "            for j in range(step):\n",
    "                bboxes_series.append(bbox)\n",
    "        return bboxes_series\n",
    "    \n",
    "    def lsk_2d_prediction(self, pid: int, sid: int, data: np.ndarray)-> np.ndarray:\n",
    "        bboxes = self.create_bbox(data) # bounding boxを作成\n",
    "        self.bboxes = bboxes\n",
    "        data, bboxes = self.z_indices_cut(pid, sid, data, bboxes)\n",
    "        if len(data) == 0:\n",
    "            return np.zeros((1, self.CFG_LSK_2D.n_class))\n",
    "        lsk_2d_iterator = self.pseudo_iterator(self.CFG_LSK_2D, data, bboxes)\n",
    "        pred = cls_inference(self.CFG_LSK_2D, self.lsk_2d_models, lsk_2d_iterator)\n",
    "        # pred = self.be_prediction_postprocess(pred)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solid_organ = load_df(CFG_LSK)\n",
    "# fold 0のpatient_idを取得\n",
    "pids = df_solid_organ[df_solid_organ[\"fold\"] == 0][\"patient_id\"].unique()\n",
    "df_all = pd.read_csv(os.path.join(CFG_INF.base_dir, 'train.csv'))\n",
    "train_pids = df_solid_organ[df_solid_organ[\"fold\"] != 0][\"patient_id\"].unique()\n",
    "valid_pids = df_solid_organ[df_solid_organ[\"fold\"] == 0][\"patient_id\"].unique()\n",
    "df_train = df_all[df_all[\"patient_id\"].isin(train_pids)].reset_index(drop=True)\n",
    "df_valid = df_all[df_all[\"patient_id\"].isin(valid_pids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_instance = Inference(CFG_INF, CFG_LSK, CFG_BE, CFG_BODY, CFG_LSK_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [12:34<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for pid in tqdm(df_valid['patient_id'].to_list()):\n",
    "    result = inference_instance(pid)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# resultsを保存\n",
    "dir_ = os.path.join(CFG_INF.model_save_dir, CFG_INF.exp_name)\n",
    "os.makedirs(dir_, exist_ok=True)#\n",
    "path = os.path.join(dir_, \"lsk_2d_results.pkl\")\n",
    "with open(path, 'wb') as f:\n",
    "   pickle.dump(results, f)\n",
    "\n",
    "# resultsを読み込み\n",
    "# with open(path, 'rb') as f:\n",
    "#    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp068 result\n",
    "import pickle\n",
    "path = \"outputs/exp_070/results_seg004_lsk056_be068.pkl\"\n",
    "with open(path, 'rb') as f:\n",
    "    exp068_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_prediction(pred: np.ndarray)->np.ndarray:\n",
    "    \"連続する10スライスの予測値が十分に大きい場合、それにふさわしい予測値を返す.\"\n",
    "    ret = 0\n",
    "    slices = 10\n",
    "    for i in range(0,len(pred)-slices):\n",
    "        ret = max(ret, np.mean(pred[i:i+slices]))\n",
    "            # print(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "525it [00:00, 563.37it/s]\n"
     ]
    }
   ],
   "source": [
    "result_clean = []\n",
    "for idx, (pid, result) in tqdm(enumerate(zip(df_valid['patient_id'].to_list(), results))):\n",
    "    result_patient = {\n",
    "        \"patient_id\": pid,\n",
    "    }\n",
    "    for label, pred in result.items():\n",
    "        series_max = []\n",
    "        for pred_series in pred:\n",
    "            # (1, slices) -> (slices,)\n",
    "            pred_series = pred_series[0]\n",
    "            # p = 90\n",
    "            # pred_series_to_one = np.percentile(pred_series, p)\n",
    "\n",
    "            pred_series = pred_series[2:-2]\n",
    "            pred_series_to_one = get_numerical_prediction(pred_series)\n",
    "            # pred_series_to_one = np.mean(pred_series)\n",
    "            \n",
    "            series_max.append(pred_series_to_one)\n",
    "        result_patient[label] = np.max(series_max)\n",
    "    result_clean.append(result_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_submission_format(result_clean: list):\n",
    "    \"\"\"提出形式に変換.\"\"\"\n",
    "    result_clean_converted = []\n",
    "    for patient_result in result_clean:\n",
    "        for organ in [\"liver\", \"spleen\", \"kidney\"]:\n",
    "            patient_result[f\"{organ}_healthy\"] = max(0, 1 - (patient_result[f\"{organ}_low\"] + patient_result[f\"{organ}_high\"]))\n",
    "        result_clean_converted.append(patient_result)\n",
    "    return result_clean_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_result = convert_submission_format(result_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(converted_result)):\n",
    "    # for key in [\"liver\", \"spleen\", \"kidney\"]:\n",
    "    #     for key2 in [\"healthy\", \"low\", \"high\"]:\n",
    "            # converted_result[i][f\"{key}_{key2}\"] = lsk_results[i][f\"{key}_{key2}\"]\n",
    "    converted_result[i][\"bowel_healthy\"] = 1 - 0.02034\n",
    "    converted_result[i][\"bowel_injury\"] = 0.02034\n",
    "    converted_result[i][\"extravasation_healthy\"] = 1 - 0.06\n",
    "    converted_result[i][\"extravasation_injury\"] = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bowel_healthy</th>\n",
       "      <th>bowel_injury</th>\n",
       "      <th>extravasation_healthy</th>\n",
       "      <th>extravasation_injury</th>\n",
       "      <th>kidney_healthy</th>\n",
       "      <th>kidney_low</th>\n",
       "      <th>kidney_high</th>\n",
       "      <th>liver_healthy</th>\n",
       "      <th>liver_low</th>\n",
       "      <th>liver_high</th>\n",
       "      <th>spleen_healthy</th>\n",
       "      <th>spleen_low</th>\n",
       "      <th>spleen_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10007</td>\n",
       "      <td>0.97966</td>\n",
       "      <td>0.02034</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.989043</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.997849</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.988533</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>0.003077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10205</td>\n",
       "      <td>0.97966</td>\n",
       "      <td>0.02034</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.975909</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.021666</td>\n",
       "      <td>0.969421</td>\n",
       "      <td>0.028423</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>0.946226</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.037705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10275</td>\n",
       "      <td>0.97966</td>\n",
       "      <td>0.02034</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.998248</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.998418</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.946162</td>\n",
       "      <td>0.049549</td>\n",
       "      <td>0.004289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10430</td>\n",
       "      <td>0.97966</td>\n",
       "      <td>0.02034</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.912522</td>\n",
       "      <td>0.014428</td>\n",
       "      <td>0.073050</td>\n",
       "      <td>0.799782</td>\n",
       "      <td>0.155365</td>\n",
       "      <td>0.044853</td>\n",
       "      <td>0.747891</td>\n",
       "      <td>0.198656</td>\n",
       "      <td>0.053453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10494</td>\n",
       "      <td>0.97966</td>\n",
       "      <td>0.02034</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516799</td>\n",
       "      <td>0.771134</td>\n",
       "      <td>0.675156</td>\n",
       "      <td>0.285715</td>\n",
       "      <td>0.039129</td>\n",
       "      <td>0.491224</td>\n",
       "      <td>0.184704</td>\n",
       "      <td>0.324072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10696</td>\n",
       "      <td>0.97966</td>\n",
       "      <td>0.02034</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.960268</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.035050</td>\n",
       "      <td>0.988596</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>0.990792</td>\n",
       "      <td>0.005703</td>\n",
       "      <td>0.003506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10987</td>\n",
       "      <td>0.97966</td>\n",
       "      <td>0.02034</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.854432</td>\n",
       "      <td>0.042438</td>\n",
       "      <td>0.103130</td>\n",
       "      <td>0.998650</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.888448</td>\n",
       "      <td>0.107065</td>\n",
       "      <td>0.004487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11130</td>\n",
       "      <td>0.97966</td>\n",
       "      <td>0.02034</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.332696</td>\n",
       "      <td>0.482976</td>\n",
       "      <td>0.184328</td>\n",
       "      <td>0.566438</td>\n",
       "      <td>0.205397</td>\n",
       "      <td>0.228165</td>\n",
       "      <td>0.304769</td>\n",
       "      <td>0.422935</td>\n",
       "      <td>0.272296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11139</td>\n",
       "      <td>0.97966</td>\n",
       "      <td>0.02034</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.936948</td>\n",
       "      <td>0.058519</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>0.990197</td>\n",
       "      <td>0.008406</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.850482</td>\n",
       "      <td>0.077799</td>\n",
       "      <td>0.071719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11378</td>\n",
       "      <td>0.97966</td>\n",
       "      <td>0.02034</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.637505</td>\n",
       "      <td>0.324320</td>\n",
       "      <td>0.038176</td>\n",
       "      <td>0.743601</td>\n",
       "      <td>0.163496</td>\n",
       "      <td>0.092903</td>\n",
       "      <td>0.862073</td>\n",
       "      <td>0.115688</td>\n",
       "      <td>0.022240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  bowel_healthy  bowel_injury  extravasation_healthy  \\\n",
       "0       10007        0.97966       0.02034                   0.94   \n",
       "1       10205        0.97966       0.02034                   0.94   \n",
       "2       10275        0.97966       0.02034                   0.94   \n",
       "3       10430        0.97966       0.02034                   0.94   \n",
       "4       10494        0.97966       0.02034                   0.94   \n",
       "5       10696        0.97966       0.02034                   0.94   \n",
       "6       10987        0.97966       0.02034                   0.94   \n",
       "7       11130        0.97966       0.02034                   0.94   \n",
       "8       11139        0.97966       0.02034                   0.94   \n",
       "9       11378        0.97966       0.02034                   0.94   \n",
       "\n",
       "   extravasation_injury  kidney_healthy  kidney_low  kidney_high  \\\n",
       "0                  0.06        0.989043    0.003915     0.007042   \n",
       "1                  0.06        0.975909    0.002425     0.021666   \n",
       "2                  0.06        0.998248    0.000295     0.001458   \n",
       "3                  0.06        0.912522    0.014428     0.073050   \n",
       "4                  0.06        0.000000    0.516799     0.771134   \n",
       "5                  0.06        0.960268    0.004683     0.035050   \n",
       "6                  0.06        0.854432    0.042438     0.103130   \n",
       "7                  0.06        0.332696    0.482976     0.184328   \n",
       "8                  0.06        0.936948    0.058519     0.004533   \n",
       "9                  0.06        0.637505    0.324320     0.038176   \n",
       "\n",
       "   liver_healthy  liver_low  liver_high  spleen_healthy  spleen_low  \\\n",
       "0       0.997849   0.001469    0.000682        0.988533    0.008390   \n",
       "1       0.969421   0.028423    0.002157        0.946226    0.016069   \n",
       "2       0.998418   0.000925    0.000657        0.946162    0.049549   \n",
       "3       0.799782   0.155365    0.044853        0.747891    0.198656   \n",
       "4       0.675156   0.285715    0.039129        0.491224    0.184704   \n",
       "5       0.988596   0.003810    0.007594        0.990792    0.005703   \n",
       "6       0.998650   0.000887    0.000463        0.888448    0.107065   \n",
       "7       0.566438   0.205397    0.228165        0.304769    0.422935   \n",
       "8       0.990197   0.008406    0.001397        0.850482    0.077799   \n",
       "9       0.743601   0.163496    0.092903        0.862073    0.115688   \n",
       "\n",
       "   spleen_high  \n",
       "0     0.003077  \n",
       "1     0.037705  \n",
       "2     0.004289  \n",
       "3     0.053453  \n",
       "4     0.324072  \n",
       "5     0.003506  \n",
       "6     0.004487  \n",
       "7     0.272296  \n",
       "8     0.071719  \n",
       "9     0.022240  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(converted_result)\n",
    "# submission = pd.DataFrame(results)\n",
    "order = CFG_INF.df.columns.tolist()\n",
    "if \"any_injury\" in order:\n",
    "    order.remove(\"any_injury\")\n",
    "submission = submission[order]\n",
    "submission[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    525.000000\n",
       "mean       0.076322\n",
       "std        0.112525\n",
       "min        0.000000\n",
       "25%        0.007352\n",
       "50%        0.027624\n",
       "75%        0.094566\n",
       "max        0.694822\n",
       "Name: liver_low, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"liver_low\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_hack(df:pd.DataFrame)->pd.DataFrame:\n",
    "    \"\"\"bowel, liver, spleen, kidney.いずれかが高い予測値を持つとき、extravasationも合併している確率が高い.\"\"\"\n",
    "    cols = [\"extravasation_injury\", \"liver_low\", \"liver_high\", \"spleen_low\", \"spleen_high\", \"kidney_low\", \"kidney_high\"]\n",
    "    # \"extravasation_injury\", \"bowel_injury\", \n",
    "    df[\"extravasation_injury\"] = df[cols].max(axis=1)\n",
    "    df[\"extravasation_healthy\"] = 1 - df[\"extravasation_injury\"]\n",
    "    return df\n",
    "# submission = metric_hack(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "x = submission[\"extravasation_injury\"]\n",
    "y = df_valid[\"extravasation_injury\"]\n",
    "fpr, tpr, thresholds = roc_curve(y, x)\n",
    "auc = roc_auc_score(y, x)\n",
    "plt.plot(fpr, tpr, marker='o')\n",
    "plt.title(auc)\n",
    "plt.xlabel('FPR: False positive rate')\n",
    "plt.ylabel('TPR: True positive rate')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean: 0.707\n",
    "99%tile: 0.72\n",
    "95%tile:0.69\n",
    "90%tile: 0.68\n",
    "get_numerical_prediction: 0.718"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bowel: 0.1654\n",
      "extravasation: 0.8514\n",
      "kidney: 0.7129\n",
      "liver: 0.8789\n",
      "spleen: 0.9942\n",
      "any_injury: 1.1569\n",
      "mean: 0.7933\n",
      "Training score without scaling: 0.7933\n"
     ]
    }
   ],
   "source": [
    "# add weight\n",
    "solution_train = create_training_solution(df_valid)\n",
    "\n",
    "no_scale_score = score(solution_train.copy(),submission.copy(),'patient_id')\n",
    "print(f'Training score without scaling: {no_scale_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bowel: 0.1596\n",
      "extravasation: 0.7108\n",
      "kidney: 0.7576\n",
      "liver: 0.8500\n",
      "spleen: 1.0300\n",
      "any_injury: 0.8747\n",
      "mean: 0.7304\n",
      "Training score with weight scaling: 0.7304\n"
     ]
    }
   ],
   "source": [
    "# Group by different sample weights\n",
    "scale_by_2 = ['bowel_injury', 'kidney_low','liver_low','spleen_low']\n",
    "scale_by_4 = ['kidney_high','liver_high','spleen_high']\n",
    "scale_by_6 = ['extravasation_injury']\n",
    "\n",
    "# Scale factors based on described metric \n",
    "sf_2 = 2\n",
    "sf_4 = 4\n",
    "sf_6 = 2\n",
    "\n",
    "# Reset the prediction\n",
    "y_pred = submission.copy()\n",
    "\n",
    "# Scale each target \n",
    "y_pred[scale_by_2] *=sf_2\n",
    "y_pred[scale_by_4] *=sf_4\n",
    "y_pred[scale_by_6] *=sf_6\n",
    "\n",
    "weight_scale_score = score(solution_train.copy(),y_pred.copy(),'patient_id')\n",
    "print(f'Training score with weight scaling: {weight_scale_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1466604250.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [83]\u001b[0;36m\u001b[0m\n\u001b[0;31m    Training score with weight scaling: 0.4495\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "bowel: 0.1596\n",
    "extravasation: 0.5070\n",
    "kidney: 0.3229\n",
    "liver: 0.5524\n",
    "spleen: 0.5481\n",
    "any_injury: 0.6071\n",
    "mean: 0.4495\n",
    "Training score with weight scaling: 0.4495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowel: 0.1596\n",
    "extravasation: 0.5237\n",
    "kidney: 0.3229\n",
    "liver: 0.5524\n",
    "spleen: 0.5928\n",
    "any_injury: 0.6061\n",
    "mean: 0.4596\n",
    "Training score with weight scaling: 0.4596"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bowel: 0.1508\n",
    "extravasation: 0.5704\n",
    "kidney: 0.3229\n",
    "liver: 0.5524\n",
    "spleen: 0.5928\n",
    "any_injury: 0.6130\n",
    "mean: 0.4671\n",
    "Training score with weight scaling: 0.4671"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean, sf30\n",
    "bowel: 0.1508\n",
    "extravasation: 0.5519\n",
    "kidney: 0.3229\n",
    "liver: 0.5524\n",
    "spleen: 0.5928\n",
    "any_injury: 0.6203\n",
    "mean: 0.4652\n",
    "Training score with weight scaling: 0.4652"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
